"""
Enhanced POMDP Parameters Generator for Supply Chain Resilience

ğŸ”§ ä¿®æ”¹ç‰ˆæœ¬ï¼šæ”¯æŒéšæœºå®éªŒ
- ç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç çš„èŠ‚ç‚¹ç‰¹å®šæ¦‚ç‡
- æ”¹ä¸ºå‚æ•°åŒ–å…¬å¼åŠ¨æ€ç”Ÿæˆ
- æ”¯æŒä»»æ„èŠ‚ç‚¹æ•°ã€çŠ¶æ€æ•°ã€åŠ¨ä½œæ•°
- è°ƒç”¨ R1_network_generate4.py

Current Date and Time (UTC): 2025-10-28 12:48:41
Current User's Login: dyy21zyy
"""

import numpy as np
import pandas as pd
from scipy.stats import dirichlet
import warnings

warnings.filterwarnings('ignore')

# ğŸ”§ ä¿®æ”¹ç‚¹1ï¼šè°ƒç”¨ä¿®æ”¹åçš„ç½‘ç»œç”Ÿæˆå™¨
from R1_network_generate4 import generate_supply_chain_network


class POMDPParametersGenerator:
    """
    POMDPå‚æ•°ç”Ÿæˆå™¨
    ç”ŸæˆçŠ¶æ€è½¬ç§»æ¦‚ç‡çŸ©é˜µå’Œè§‚å¯Ÿæ¦‚ç‡çŸ©é˜µ
    æ‰€æœ‰å…³é”®å‚æ•°éƒ½ä»ä¸»å‡½æ•°configä¼ å…¥ï¼Œæ— é»˜è®¤å€¼

    ğŸ”§ ä¿®æ”¹ç‰ˆæœ¬ç‰¹æ€§ï¼š
    1. ç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç èŠ‚ç‚¹ç‰¹å®šæ¦‚ç‡
    2. ä½¿ç”¨å‚æ•°åŒ–å…¬å¼åŠ¨æ€ç”Ÿæˆ
    3. æ”¯æŒä»»æ„èŠ‚ç‚¹æ•°ã€å±‚æ•°
    4. ä¿è¯èŠ‚ç‚¹é—´æœ‰å·®å¼‚ä½†ä¸ç¡¬ç¼–ç 
    """

    def __init__(self, network_data, num_states, num_actions, seed):
        """
        åˆå§‹åŒ–POMDPå‚æ•°ç”Ÿæˆå™¨
        æ‰€æœ‰å‚æ•°éƒ½å¿…é¡»ä»ä¸»å‡½æ•°ä¼ å…¥ï¼Œæ— é»˜è®¤å€¼

        Args:
            network_data: ç½‘ç»œæ•°æ®
            num_states: çŠ¶æ€æ•°é‡ï¼ˆä»ä¸»å‡½æ•°configä¼ å…¥ï¼Œå¿…é¡»ï¼‰
            num_actions: è¡ŒåŠ¨æ•°é‡ï¼ˆä»ä¸»å‡½æ•°configä¼ å…¥ï¼Œå¿…é¡»ï¼‰
            seed: éšæœºç§å­ï¼ˆä»ä¸»å‡½æ•°configä¼ å…¥ï¼Œå¿…é¡»ï¼‰
        """
        # éªŒè¯æ‰€æœ‰å¿…é¡»å‚æ•°
        required_params = {
            'num_states': num_states,
            'num_actions': num_actions,
            'seed': seed
        }

        for param_name, param_value in required_params.items():
            if param_value is None:
                raise ValueError(
                    f"Required parameter '{param_name}' cannot be None - must be provided by main function config")

        print(f"ğŸ”§ Initializing Enhanced POMDP Parameters Generator (Random Experiment Version)")
        print(f"   All parameters from main function config:")
        print(f"   - num_states: {num_states}")
        print(f"   - num_actions: {num_actions}")
        print(f"   - seed: {seed}")

        self.seed = seed
        np.random.seed(seed)

        # ä»ä¸»å‡½æ•°configä¼ å…¥çš„å‚æ•°ï¼ˆæ— é»˜è®¤å€¼ï¼‰
        self.num_states = num_states  # |R_k^t|
        self.num_actions = num_actions  # |A_k^t|

        # è§£åŒ…ç½‘ç»œæ•°æ®ï¼ˆæ¥è‡ªR1_network_generate4ï¼‰
        (self.network, self.layer_info, self.temporal_network,
         self.temporal_node_info, self.parent_dict,
         self.independent_nodes, self.other_nodes,
         self.parent_node_dic, self.C_dic, self.G_dic) = network_data

        self.num_nodes = self.layer_info['num_nodes']
        self.num_observations = self.num_states  # |O_k^t| = |R_k^t| (è§‚å¯Ÿç©ºé—´ç­‰åŒäºçŠ¶æ€ç©ºé—´)

        # éªŒè¯ç½‘ç»œæ•°æ®ä¸€è‡´æ€§
        self._validate_network_data()

        # å®šä¹‰çŠ¶æ€ã€è¡ŒåŠ¨å’Œè§‚å¯Ÿçš„å«ä¹‰
        self._define_spaces()

        # å­˜å‚¨ç”Ÿæˆçš„æ¦‚ç‡çŸ©é˜µ
        self.transition_probabilities = {}  # P(r^{t+1} | r^t, a^t)
        self.observation_probabilities = {}  # P(o^t | r^t, a^{t-1})

        print("POMDP Parameters Generator Initialized")
        print(f"Configuration: {self.num_nodes} nodes, {self.num_states} states, {self.num_actions} actions")

    def _validate_network_data(self):
        """éªŒè¯ç½‘ç»œæ•°æ®çš„å®Œæ•´æ€§"""
        print("ğŸ” Validating network data consistency...")

        required_components = [
            'network', 'layer_info', 'temporal_network', 'temporal_node_info',
            'parent_dict', 'independent_nodes', 'other_nodes', 'parent_node_dic',
            'C_dic', 'G_dic'
        ]

        for component in required_components:
            if not hasattr(self, component):
                raise ValueError(f"Missing network component: {component}")

        # éªŒè¯èŠ‚ç‚¹æ•°é‡ä¸€è‡´æ€§
        expected_nodes = self.layer_info['num_nodes']
        if self.network.shape[0] != expected_nodes:
            raise ValueError(f"Network dimension mismatch: expected {expected_nodes}, got {self.network.shape[0]}")

        print(f"   âœ… Network validation passed")
        print(f"   - Spatial network: {self.network.shape}")
        print(f"   - Temporal network: {self.temporal_network.shape}")
        print(f"   - Independent nodes: {self.independent_nodes}")
        print(f"   - Other nodes: {self.other_nodes}")

    def _define_spaces(self):
        """
        å®šä¹‰çŠ¶æ€ç©ºé—´ã€è¡ŒåŠ¨ç©ºé—´å’Œè§‚å¯Ÿç©ºé—´çš„å«ä¹‰
        åŸºäºä¸»å‡½æ•°ä¼ å…¥çš„num_stateså’Œnum_actionså‚æ•°
        """

        # çŠ¶æ€ç©ºé—´ R_k^t (åŸºäºå±¥è¡Œç‡çš„ç¦»æ•£åŒ–)
        if self.num_states == 2:
            self.state_definitions = {
                0: "Good (High Fulfillment Rate â‰¥ 0.5)",
                1: "Poor (Low Fulfillment Rate < 0.5)"
            }
        elif self.num_states == 3:
            self.state_definitions = {
                0: "Excellent (Fulfillment Rate â‰¥ 0.67)",
                1: "Moderate (0.33 â‰¤ Fulfillment Rate < 0.67)",
                2: "Poor (Fulfillment Rate < 0.33)"
            }
        elif self.num_states == 4:
            self.state_definitions = {
                0: "Excellent (Fulfillment Rate â‰¥ 0.75)",
                1: "Good (0.5 â‰¤ Fulfillment Rate < 0.75)",
                2: "Fair (0.25 â‰¤ Fulfillment Rate < 0.5)",
                3: "Poor (Fulfillment Rate < 0.25)"
            }
        else:
            self.state_definitions = {i: f"State_{i}" for i in range(self.num_states)}

        # è¡ŒåŠ¨ç©ºé—´ A_k^t (åŸºäºä¸»å‡½æ•°å‚æ•°)
        if self.num_actions == 2:
            self.action_definitions = {
                0: "Maintain Current Operations (No Action)",
                1: "Increase Safety Stock"
            }
        elif self.num_actions == 3:
            self.action_definitions = {
                0: "Maintain Current Operations (No Action)",
                1: "mild intervention",
                2: "intense intervention"
            }
        else:
            self.action_definitions = {i: f"Action_{i}" for i in range(self.num_actions)}

        # è§‚å¯Ÿç©ºé—´ O_k^t (ä¸çŠ¶æ€ç©ºé—´ç›¸åŒ)
        self.observation_definitions = self.state_definitions.copy()

        print("\nğŸ”§ Space Definitions (from main config):")
        print("States (R_k^t):")
        for i, desc in self.state_definitions.items():
            print(f"  {i}: {desc}")
        print("Actions (A_k^t):")
        for i, desc in self.action_definitions.items():
            print(f"  {i}: {desc}")
        print("Observations (O_k^t):")
        for i, desc in self.observation_definitions.items():
            print(f"  {i}: {desc}")

    def _get_node_characteristics(self, node):
        """
        è·å–èŠ‚ç‚¹ç‰¹å¾ï¼ˆå…¼å®¹å¤šå±‚ç½‘ç»œï¼‰

        ğŸ”§ ä¿®æ”¹ç‚¹ï¼šæ”¯æŒä»»æ„å±‚æ•°
        """
        # éå†æ‰€æœ‰å±‚ï¼Œæ‰¾åˆ°èŠ‚ç‚¹æ‰€å±å±‚
        for layer_idx in range(1, self.layer_info['num_layers'] + 1):
            layer_key = f'layer{layer_idx}'
            if layer_key in self.layer_info:
                start, end, name = self.layer_info[layer_key]
                if start <= node < end:
                    return name, node - start  # è¿”å›å±‚åå’Œå±‚å†…ç´¢å¼•

        return 'Unknown', 0

    def generate_transition_probabilities(self):
        """
        ç”ŸæˆçŠ¶æ€è½¬ç§»æ¦‚ç‡çŸ©é˜µ P(r^{t+1} | r^t, a^t)
        åŸºäºä¸»å‡½æ•°ä¼ å…¥çš„num_stateså’Œnum_actionså‚æ•°

        ğŸ”§ ä¿®æ”¹ç‰ˆæœ¬ï¼š
        - ç§»é™¤ç¡¬ç¼–ç çš„ç‰¹æ®ŠèŠ‚ç‚¹å¤„ç†
        - ä½¿ç”¨å‚æ•°åŒ–å…¬å¼åŠ¨æ€ç”Ÿæˆ
        """
        print(f"\nğŸ”§ Generating ENHANCED State Transition Probabilities P(r^{{t+1}} | r^t, a^t)")
        print(f"   Matrix dimensions from main config: ({self.num_states}, {self.num_actions}, {self.num_states})")
        print(f"   Using parameterized formulas (no hardcoded node-specific values)")
        print("=" * 70)

        self.transition_probabilities = {}

        for node in range(self.num_nodes):
            node_type, node_idx = self._get_node_characteristics(node)

            print(f"\nğŸ“ Node {node} ({node_type} {node_idx}) - Parameterized Probabilities")

            # ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ›å»ºè½¬ç§»æ¦‚ç‡çŸ©é˜µ
            # ç»´åº¦: [current_state, action, next_state] - åŸºäºä¸»å‡½æ•°å‚æ•°
            transition_matrix = np.zeros((self.num_states, self.num_actions, self.num_states))

            for current_state in range(self.num_states):
                for action in range(self.num_actions):
                    # æ ¹æ®å½“å‰çŠ¶æ€å’Œè¡ŒåŠ¨ç”Ÿæˆä¸‹ä¸€çŠ¶æ€çš„æ¦‚ç‡åˆ†å¸ƒ
                    next_state_probs = self._compute_transition_probabilities(
                        node, node_type, current_state, action
                    )

                    transition_matrix[current_state, action, :] = next_state_probs

                    print(
                        f"  P(r^{{t+1}} | r^t={current_state}, a^t={action}): {[f'{p:.3f}' for p in next_state_probs]}")

            self.transition_probabilities[node] = transition_matrix

            # éªŒè¯æ¦‚ç‡çŸ©é˜µçš„æœ‰æ•ˆæ€§
            self._validate_transition_matrix(transition_matrix, node)

        print(f"\nâœ… State transition probabilities generated successfully!")
        print(f"   Generated for {len(self.transition_probabilities)} nodes")
        print(f"   Each matrix shape: ({self.num_states}, {self.num_actions}, {self.num_states})")
        return self.transition_probabilities

    def _compute_transition_probabilities(self, node, node_type, current_state, action):
        """
        ğŸ”§ æ ¸å¿ƒä¿®æ”¹ï¼šå‚æ•°åŒ–è®¡ç®—è½¬ç§»æ¦‚ç‡ï¼ˆç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç ï¼‰

        è®¡ç®—ç­–ç•¥ï¼š
        1. åŸºäºèŠ‚ç‚¹å“ˆå¸Œç”ŸæˆèŠ‚ç‚¹ç‰¹å¼‚æ€§å› å­
        2. åŸºäºèŠ‚ç‚¹ç±»å‹è°ƒæ•´æ¦‚ç‡å€¾å‘
        3. åŸºäºåŠ¨ä½œè®¡ç®—æ”¹å–„/æ¶åŒ–æ•ˆæœ
        4. ä¸å†æœ‰ä»»ä½•èŠ‚ç‚¹çš„ç¡¬ç¼–ç ç‰¹æ®Šå¤„ç†

        çŠ¶æ€å®šä¹‰ï¼š0=æœ€å·®çŠ¶æ€ï¼Œæ•°å­—è¶Šå¤§çŠ¶æ€è¶Šå¥½
        åŠ¨ä½œæ•ˆæœï¼ˆå¿…é¡»ä¸¥æ ¼åŒºåˆ†ï¼‰ï¼š
        - è½¬ç§»åˆ°æœ€å¥½çŠ¶æ€æ¦‚ç‡ï¼šAction 2 > Action 1 > Action 0
        - è½¬ç§»åˆ°æœ€å·®çŠ¶æ€æ¦‚ç‡ï¼šAction 0 > Action 1 > Action 2
        """

        # ğŸ”§ ç§»é™¤èŠ‚ç‚¹5çš„ç‰¹æ®Šå¤„ç†ï¼Œæ”¹ä¸ºç»Ÿä¸€å…¬å¼

        # è®¾ç½®æ¦‚ç‡è¾¹ç•Œ
        MIN_PROB = 0.1
        MAX_PROB = 0.8

        # ============================================
        # æ­¥éª¤1ï¼šç”ŸæˆèŠ‚ç‚¹ç‰¹å¼‚æ€§å› å­ï¼ˆåŸºäºå“ˆå¸Œï¼‰
        # ============================================
        # ä½¿ç”¨å¤šä¸ªè´¨æ•°ç”ŸæˆèŠ‚ç‚¹å“ˆå¸Œï¼Œç¡®ä¿èŠ‚ç‚¹é—´æœ‰å·®å¼‚
        node_hash_1 = (node * 19 + 11) % 31
        node_hash_2 = (node * 23 + 13) % 37
        node_hash_3 = (node * 29 + 17) % 41

        # èŠ‚ç‚¹åŸºç¡€å› å­ [0.0, 0.3]
        node_base_factor = (node_hash_1 / 31.0) * 0.3

        # èŠ‚ç‚¹æ³¢åŠ¨å› å­ [-0.1, +0.1]
        node_volatility = (node_hash_2 / 37.0) * 0.2 - 0.1

        # èŠ‚ç‚¹åå¥½å› å­ï¼ˆå€¾å‘å¥½çŠ¶æ€æˆ–å·®çŠ¶æ€ï¼‰[-0.15, +0.15]
        node_bias = (node_hash_3 / 41.0) * 0.3 - 0.15

        # ============================================
        # æ­¥éª¤2ï¼šèŠ‚ç‚¹ç±»å‹è°ƒæ•´
        # ============================================
        # ä¸åŒç±»å‹çš„èŠ‚ç‚¹æœ‰ä¸åŒçš„ç¨³å®šæ€§å’Œå“åº”èƒ½åŠ›
        type_factors = {
            'Suppliers': {
                'stability': 0.7,  # ç¨³å®šæ€§è¾ƒä½
                'action_response': 1.2  # å¯¹æŠ•èµ„å“åº”è¾ƒå¥½
            },
            'Manufacturers': {
                'stability': 0.75,
                'action_response': 1.3
            },
            'Intermediate_1': {  # ä¸­é—´å±‚1
                'stability': 0.8,
                'action_response': 1.15
            },
            'Intermediate_2': {  # ä¸­é—´å±‚2
                'stability': 0.82,
                'action_response': 1.1
            },
            'Retailer': {
                'stability': 0.85,  # ç¨³å®šæ€§æœ€é«˜
                'action_response': 1.4  # å¯¹æŠ•èµ„å“åº”æœ€å¥½ï¼ˆæ•ˆæœæœ€ç›´æ¥ï¼‰
            },
            'Unknown': {
                'stability': 0.75,
                'action_response': 1.0
            }
        }

        # è·å–èŠ‚ç‚¹ç±»å‹å› å­
        type_factor = type_factors.get(node_type, type_factors['Unknown'])
        stability = type_factor['stability']
        action_response = type_factor['action_response']

        # ============================================
        # æ­¥éª¤3ï¼šåŠ¨ä½œæ•ˆæœè®¡ç®—
        # ============================================
        # ä¸åŒåŠ¨ä½œå¯¹çŠ¶æ€è½¬ç§»çš„å½±å“ï¼ˆåŸºç¡€æ•ˆæœï¼‰
        action_base_effects = {
            0: {  # æ— åŠ¨ä½œ - æœ€å·®æ•ˆæœ
                'improvement': 0.05,  # æ”¹å–„å€¾å‘å¾ˆä½
                'degradation': 0.40,  # æ¶åŒ–å€¾å‘é«˜
                'stability_penalty': 0.2  # é™ä½ç¨³å®šæ€§
            },
            1: {  # Mild intervention - ä¸­ç­‰æ•ˆæœ
                'improvement': 0.25,
                'degradation': 0.15,
                'stability_penalty': 0.0
            },
            2: {  # Intense intervention - æœ€å¥½æ•ˆæœ
                'improvement': 0.45,
                'degradation': 0.05,
                'stability_penalty': 0.0
            }
        }

        # é«˜çº§åŠ¨ä½œï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if action >= 3:
            # é€’å¢æ”¹å–„æ•ˆæœ
            extra_improvement = (action - 2) * 0.08
            action_effects = {
                'improvement': min(0.55, 0.45 + extra_improvement),
                'degradation': max(0.02, 0.05 - extra_improvement * 0.3),
                'stability_penalty': 0.0
            }
        else:
            action_effects = action_base_effects.get(action, action_base_effects[0])

        # åº”ç”¨èŠ‚ç‚¹ç±»å‹çš„åŠ¨ä½œå“åº”ç³»æ•°
        action_effects['improvement'] *= action_response
        action_effects['degradation'] /= action_response

        # ============================================
        # æ­¥éª¤4ï¼šè®¡ç®—è½¬ç§»æ¦‚ç‡
        # ============================================

        if self.num_states == 2:
            # 2çŠ¶æ€ï¼š0(æœ€å·®), 1(æœ€å¥½)

            if current_state == 0:  # å½“å‰æœ€å·®çŠ¶æ€
                # åŸºç¡€ä¿æŒæœ€å·®çŠ¶æ€çš„æ¦‚ç‡
                base_worst_prob = 0.5 + node_base_factor

                # æ ¹æ®åŠ¨ä½œè°ƒæ•´
                if action == 0:  # æ— åŠ¨ä½œ
                    base_worst_prob += action_effects['degradation']
                    base_worst_prob -= action_effects['improvement']
                    base_worst_prob += action_effects['stability_penalty']
                else:  # æœ‰æŠ•èµ„
                    base_worst_prob -= action_effects['improvement']
                    base_worst_prob += action_effects['degradation']

                # åº”ç”¨èŠ‚ç‚¹åå¥½
                base_worst_prob += node_bias

                # åº”ç”¨ç¨³å®šæ€§
                base_worst_prob = base_worst_prob * (1 - stability) + 0.5 * stability

                # åº”ç”¨æ³¢åŠ¨
                base_worst_prob += node_volatility

                # é™åˆ¶èŒƒå›´
                worst_prob = np.clip(base_worst_prob, MIN_PROB, MAX_PROB)
                best_prob = 1.0 - worst_prob
                next_state_probs = np.array([worst_prob, best_prob])

            else:  # current_state == 1ï¼Œå½“å‰æœ€å¥½çŠ¶æ€
                # åœ¨å¥½çŠ¶æ€ä¸‹ï¼Œä¸åŒactionå¯¹ä¿æŒå¥½çŠ¶æ€çš„èƒ½åŠ›ä¸åŒ
                base_worst_prob = 0.3 + node_base_factor

                if action == 0:  # æ— åŠ¨ä½œ - å®¹æ˜“é€€åŒ–
                    base_worst_prob += action_effects['degradation']
                    base_worst_prob += action_effects['stability_penalty']
                else:  # æœ‰æŠ•èµ„ - å®¹æ˜“ä¿æŒ
                    base_worst_prob -= action_effects['improvement']
                    base_worst_prob += action_effects['degradation'] * 0.5

                # åº”ç”¨èŠ‚ç‚¹åå¥½ï¼ˆåå‘ï¼‰
                base_worst_prob -= node_bias

                # åº”ç”¨ç¨³å®šæ€§
                base_worst_prob = base_worst_prob * (1 - stability) + 0.2 * stability

                # åº”ç”¨æ³¢åŠ¨
                base_worst_prob += node_volatility * 0.5

                worst_prob = np.clip(base_worst_prob, MIN_PROB, MAX_PROB)
                best_prob = 1.0 - worst_prob
                next_state_probs = np.array([worst_prob, best_prob])

        elif self.num_states == 3:
            # 3çŠ¶æ€ï¼š0(æœ€å·®), 1(ä¸­ç­‰), 2(æœ€å¥½)
            next_state_probs = np.zeros(3)

            # åŸºç¡€æ¦‚ç‡åˆ†å¸ƒ
            if current_state == 0:  # æœ€å·®çŠ¶æ€
                if action == 0:  # æ— åŠ¨ä½œ
                    base_probs = [0.55 + node_base_factor, 0.30, 0.15 - node_base_factor]
                elif action == 1:  # Mild
                    base_probs = [0.30 + node_base_factor, 0.40, 0.30 - node_base_factor]
                elif action == 2:  # Intense
                    base_probs = [0.12 + node_base_factor, 0.28, 0.60 - node_base_factor]
                else:  # Advanced
                    improvement = min((action - 2) * 0.08, 0.20)
                    base_probs = [
                        max(0.08, 0.12 - improvement) + node_base_factor,
                        0.25,
                        min(0.67, 0.60 + improvement) - node_base_factor
                    ]

            elif current_state == 1:  # ä¸­ç­‰çŠ¶æ€
                if action == 0:
                    base_probs = [0.40 + node_base_factor, 0.40, 0.20 - node_base_factor]
                elif action == 1:
                    base_probs = [0.20 + node_base_factor, 0.40, 0.40 - node_base_factor]
                elif action == 2:
                    base_probs = [0.08 + node_base_factor, 0.22, 0.70 - node_base_factor]
                else:
                    improvement = min((action - 2) * 0.06, 0.15)
                    base_probs = [
                        max(0.05, 0.08 - improvement) + node_base_factor,
                        max(0.15, 0.22 - improvement),
                        min(0.80, 0.70 + improvement) - node_base_factor
                    ]

            else:  # current_state == 2ï¼Œæœ€å¥½çŠ¶æ€
                if action == 0:
                    base_probs = [0.30 + node_base_factor, 0.40, 0.30 - node_base_factor]
                elif action == 1:
                    base_probs = [0.15 + node_base_factor, 0.35, 0.50 - node_base_factor]
                elif action == 2:
                    base_probs = [0.05 + node_base_factor, 0.20, 0.75 - node_base_factor]
                else:
                    maintenance = min((action - 2) * 0.05, 0.12)
                    base_probs = [
                        max(0.03, 0.05 - maintenance) + node_base_factor,
                        max(0.12, 0.20 - maintenance),
                        min(0.85, 0.75 + maintenance) - node_base_factor
                    ]

            # åº”ç”¨èŠ‚ç‚¹åå¥½å’Œæ³¢åŠ¨
            adjustments = np.array([node_bias, 0, -node_bias]) + np.array([node_volatility, 0, -node_volatility])
            adjustments *= (1 - stability)  # ç¨³å®šæ€§è¶Šé«˜ï¼Œè°ƒæ•´è¶Šå°

            next_state_probs = np.array(base_probs) + adjustments

        else:  # num_states >= 4
            # å¤šçŠ¶æ€æƒ…å†µï¼šåŸºäºå½“å‰çŠ¶æ€å’ŒåŠ¨ä½œçš„é€šç”¨å…¬å¼
            next_state_probs = np.zeros(self.num_states)
            best_state = self.num_states - 1

            # è®¡ç®—æ”¹å–„å’Œæ¶åŒ–å€¾å‘
            if action == 0:  # æ— åŠ¨ä½œ
                improvement_tendency = 0.05
                degradation_tendency = 0.40
            elif action == 1:
                improvement_tendency = 0.25
                degradation_tendency = 0.15
            elif action == 2:
                improvement_tendency = 0.45
                degradation_tendency = 0.05
            else:
                improvement_tendency = min(0.60, 0.45 + (action - 2) * 0.08)
                degradation_tendency = max(0.02, 0.05 - (action - 2) * 0.02)

            # åº”ç”¨èŠ‚ç‚¹å“åº”
            improvement_tendency *= action_response
            degradation_tendency /= action_response

            # åˆ†é…æ¦‚ç‡
            # æœ€å·®çŠ¶æ€
            next_state_probs[0] = degradation_tendency + node_base_factor
            # æœ€å¥½çŠ¶æ€
            next_state_probs[best_state] = improvement_tendency - node_base_factor
            # ä¸­é—´çŠ¶æ€
            remaining = 1.0 - next_state_probs[0] - next_state_probs[best_state]
            if self.num_states > 2:
                middle_states = self.num_states - 2
                for i in range(1, best_state):
                    # æ ¹æ®è·ç¦»å½“å‰çŠ¶æ€çš„è¿œè¿‘åˆ†é…æ¦‚ç‡
                    distance = abs(i - current_state)
                    weight = 1.0 / (1.0 + distance)
                    next_state_probs[i] = remaining * weight / middle_states

        # ============================================
        # æ­¥éª¤5ï¼šå½’ä¸€åŒ–å’ŒéªŒè¯
        # ============================================
        next_state_probs = np.clip(next_state_probs, MIN_PROB, MAX_PROB)

        # å½’ä¸€åŒ–
        prob_sum = np.sum(next_state_probs)
        if prob_sum > 0:
            next_state_probs = next_state_probs / prob_sum
        else:
            next_state_probs = np.ones(self.num_states) / self.num_states

        # ç²¾ç¡®åˆ°å°æ•°ç‚¹åä¸€ä½
        next_state_probs = np.round(next_state_probs, 1)

        # æœ€ç»ˆå½’ä¸€åŒ–æ£€æŸ¥
        final_sum = np.sum(next_state_probs)
        if not np.isclose(final_sum, 1.0, atol=0.05):
            diff = 1.0 - final_sum
            max_idx = np.argmax(next_state_probs)
            next_state_probs[max_idx] += diff
            next_state_probs = np.clip(next_state_probs, MIN_PROB, MAX_PROB)
            next_state_probs = next_state_probs / np.sum(next_state_probs)
            next_state_probs = np.round(next_state_probs, 1)

        return next_state_probs

    def _validate_transition_matrix(self, transition_matrix, node):
        """éªŒè¯è½¬ç§»çŸ©é˜µçš„æœ‰æ•ˆæ€§"""
        print(f"ğŸ“Š éªŒè¯èŠ‚ç‚¹ {node} çš„è½¬ç§»æ¦‚ç‡çŸ©é˜µ...")

        for s in range(self.num_states):
            print(f"  å½“å‰çŠ¶æ€ {s}:")

            # æ”¶é›†ä¸åŒåŠ¨ä½œçš„è½¬ç§»æ¦‚ç‡ç”¨äºæ¯”è¾ƒ
            action_effects = {}

            for a in range(self.num_actions):
                probs = transition_matrix[s, a, :]
                prob_sum = np.sum(probs)

                # æ£€æŸ¥æ¦‚ç‡å’Œ
                if not np.isclose(prob_sum, 1.0, rtol=1e-2):
                    print(f"    âš ï¸  åŠ¨ä½œ {a} - æ¦‚ç‡å’Œ: {prob_sum:.3f}")

                # æ£€æŸ¥è´Ÿæ¦‚ç‡
                if np.any(probs < 0):
                    print(f"    âš ï¸  åŠ¨ä½œ {a} - å­˜åœ¨è´Ÿæ¦‚ç‡")

                # è®°å½•å…³é”®æ¦‚ç‡
                worst_state_prob = probs[0]  # è½¬ç§»åˆ°æœ€å·®çŠ¶æ€(0)çš„æ¦‚ç‡
                best_state_prob = probs[-1]  # è½¬ç§»åˆ°æœ€å¥½çŠ¶æ€çš„æ¦‚ç‡
                action_effects[a] = {
                    'worst': worst_state_prob,
                    'best': best_state_prob
                }

                print(f"    åŠ¨ä½œ{a}: æœ€å·®çŠ¶æ€æ¦‚ç‡={worst_state_prob:.1f}, æœ€å¥½çŠ¶æ€æ¦‚ç‡={best_state_prob:.1f}")

            # éªŒè¯åŠ¨ä½œæ•ˆæœæ’åº
            if len(action_effects) >= 3:
                # éªŒè¯è½¬ç§»åˆ°æœ€å·®çŠ¶æ€æ¦‚ç‡æ’åº: Action 0 > Action 1 > Action 2
                worst_0 = action_effects[0]['worst']
                worst_1 = action_effects[1]['worst'] if 1 in action_effects else 0
                worst_2 = action_effects[2]['worst'] if 2 in action_effects else 0

                print(f"    ğŸ” è½¬ç§»åˆ°æœ€å·®çŠ¶æ€æ¦‚ç‡æ’åºéªŒè¯:")
                print(f"       Action 0: {worst_0:.1f} (åº”è¯¥æœ€é«˜)")
                print(f"       Action 1: {worst_1:.1f} (åº”è¯¥ä¸­ç­‰)")
                print(f"       Action 2: {worst_2:.1f} (åº”è¯¥æœ€ä½)")

                if worst_0 >= worst_1 >= worst_2:
                    print(f"    âœ… æœ€å·®çŠ¶æ€æ¦‚ç‡æ’åºæ­£ç¡®")
                else:
                    print(f"    âš ï¸  æœ€å·®çŠ¶æ€æ¦‚ç‡æ’åºå¯èƒ½éœ€è¦è°ƒæ•´")

                # éªŒè¯è½¬ç§»åˆ°æœ€å¥½çŠ¶æ€æ¦‚ç‡æ’åº: Action 2 > Action 1 > Action 0
                best_0 = action_effects[0]['best']
                best_1 = action_effects[1]['best'] if 1 in action_effects else 0
                best_2 = action_effects[2]['best'] if 2 in action_effects else 0

                print(f"    ğŸ” è½¬ç§»åˆ°æœ€å¥½çŠ¶æ€æ¦‚ç‡æ’åºéªŒè¯:")
                print(f"       Action 2: {best_2:.1f} (åº”è¯¥æœ€é«˜)")
                print(f"       Action 1: {best_1:.1f} (åº”è¯¥ä¸­ç­‰)")
                print(f"       Action 0: {best_0:.1f} (åº”è¯¥æœ€ä½)")

                if best_2 >= best_1 >= best_0:
                    print(f"    âœ… æœ€å¥½çŠ¶æ€æ¦‚ç‡æ’åºæ­£ç¡®")
                else:
                    print(f"    âš ï¸  æœ€å¥½çŠ¶æ€æ¦‚ç‡æ’åºå¯èƒ½éœ€è¦è°ƒæ•´")

    def generate_observation_probabilities(self):
        """
        ç”Ÿæˆè§‚å¯Ÿæ¦‚ç‡çŸ©é˜µ P(o^t | r^t, a^{t-1})

        ğŸ”§ ä¿®æ”¹ç‰ˆæœ¬ï¼šç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç ï¼Œä½¿ç”¨å‚æ•°åŒ–å…¬å¼
        """
        print(f"\nğŸ‘ï¸  Generating ENHANCED Observation Probabilities P(o^t | r^t, a^{{t-1}})")
        print(
            f"   Matrix dimensions from main config: ({self.num_states}, {self.num_actions}, {self.num_observations})")
        print(f"   Using parameterized formulas (no hardcoded node-specific values)")
        print("=" * 70)

        self.observation_probabilities = {}

        for node in range(self.num_nodes):
            node_type, node_idx = self._get_node_characteristics(node)

            print(f"\nğŸ“ Node {node} ({node_type} {node_idx}) - Parameterized Observations")

            # ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ›å»ºè§‚å¯Ÿæ¦‚ç‡çŸ©é˜µ
            # ç»´åº¦: [current_state, previous_action, observation]
            observation_matrix = np.zeros((self.num_states, self.num_actions, self.num_observations))

            for current_state in range(self.num_states):
                for prev_action in range(self.num_actions):
                    # ç”Ÿæˆè§‚å¯Ÿæ¦‚ç‡åˆ†å¸ƒ
                    obs_probs = self._compute_observation_probabilities(
                        node, node_type, current_state, prev_action
                    )

                    observation_matrix[current_state, prev_action, :] = obs_probs

                    print(f"  P(o^t | r^t={current_state}, a^{{t-1}}={prev_action}): {[f'{p:.3f}' for p in obs_probs]}")

            self.observation_probabilities[node] = observation_matrix

            # éªŒè¯è§‚å¯ŸçŸ©é˜µçš„æœ‰æ•ˆæ€§
            self._validate_observation_matrix(observation_matrix, node)

        print(f"\nâœ… Enhanced observation probabilities generated successfully!")
        print(f"   Generated for {len(self.observation_probabilities)} nodes")
        print(f"   Each matrix shape: ({self.num_states}, {self.num_actions}, {self.num_observations})")
        return self.observation_probabilities

    def _compute_observation_probabilities(self, node, node_type, current_state, prev_action):
        """
        ğŸ”§ æ ¸å¿ƒä¿®æ”¹ï¼šå‚æ•°åŒ–è®¡ç®—è§‚æµ‹æ¦‚ç‡ï¼ˆç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç ï¼‰

        è®¡ç®—ç­–ç•¥ï¼š
        1. åŸºäºèŠ‚ç‚¹å“ˆå¸Œç”Ÿæˆè§‚æµ‹ç‰¹æ€§
        2. åŸºäºå‰ä¸€æœŸåŠ¨ä½œè°ƒæ•´è§‚æµ‹å‡†ç¡®æ€§
        3. ä¸å†æœ‰ä»»ä½•èŠ‚ç‚¹çš„ç¡¬ç¼–ç ç‰¹æ®Šå¤„ç†

        Args:
            node: èŠ‚ç‚¹ç´¢å¼•
            node_type: èŠ‚ç‚¹ç±»å‹
            current_state: å½“å‰çœŸå®çŠ¶æ€
            prev_action: å‰ä¸€æœŸé‡‡å–çš„åŠ¨ä½œ

        Returns:
            obs_probs: è§‚æµ‹æ¦‚ç‡åˆ†å¸ƒï¼ˆå®Œå…¨å‚æ•°åŒ–ç”Ÿæˆï¼‰
        """

        MIN_PROB = 0.1
        MAX_PROB = 0.8

        # ğŸ”§ ç§»é™¤èŠ‚ç‚¹5çš„ç‰¹æ®Šå¤„ç†ï¼Œæ”¹ä¸ºç»Ÿä¸€å…¬å¼

        # ============================================
        # æ­¥éª¤1ï¼šç”ŸæˆèŠ‚ç‚¹è§‚æµ‹ç‰¹æ€§ï¼ˆåŸºäºå“ˆå¸Œï¼‰
        # ============================================
        # ä½¿ç”¨ä¸åŒçš„è´¨æ•°ç”Ÿæˆè§‚æµ‹ç›¸å…³çš„èŠ‚ç‚¹ç‰¹æ€§
        obs_hash_1 = (node * 31 + 7) % 43
        obs_hash_2 = (node * 37 + 11) % 47
        obs_hash_3 = (node * 41 + 13) % 53

        # èŠ‚ç‚¹åŸºç¡€è§‚æµ‹å‡†ç¡®åº¦ [0.65, 0.85]
        base_accuracy = 0.65 + (obs_hash_1 / 43.0) * 0.20

        # èŠ‚ç‚¹è§‚æµ‹å™ªå£°æ°´å¹³ [0.05, 0.20]
        noise_level = 0.05 + (obs_hash_2 / 47.0) * 0.15

        # èŠ‚ç‚¹è§‚æµ‹åå·®ï¼ˆå€¾å‘ä¹è§‚æˆ–æ‚²è§‚ï¼‰[-0.10, +0.10]
        observation_bias = (obs_hash_3 / 53.0) * 0.20 - 0.10

        # ============================================
        # æ­¥éª¤2ï¼šèŠ‚ç‚¹ç±»å‹è°ƒæ•´è§‚æµ‹èƒ½åŠ›
        # ============================================
        type_obs_factors = {
            'Suppliers': {
                'accuracy_bonus': 0.00,
                'noise_reduction': 0.90
            },
            'Manufacturers': {
                'accuracy_bonus': 0.05,
                'noise_reduction': 0.85
            },
            'Intermediate_1': {
                'accuracy_bonus': 0.03,
                'noise_reduction': 0.88
            },
            'Intermediate_2': {
                'accuracy_bonus': 0.04,
                'noise_reduction': 0.86
            },
            'Retailer': {
                'accuracy_bonus': 0.08,
                'noise_reduction': 0.80
            },
            'Unknown': {
                'accuracy_bonus': 0.00,
                'noise_reduction': 1.00
            }
        }

        type_factor = type_obs_factors.get(node_type, type_obs_factors['Unknown'])
        base_accuracy += type_factor['accuracy_bonus']
        noise_level *= type_factor['noise_reduction']

        # ============================================
        # æ­¥éª¤3ï¼šå‰ä¸€æœŸåŠ¨ä½œå¯¹è§‚æµ‹çš„å½±å“
        # ============================================
        # æŠ•èµ„ä¼šæé«˜è§‚æµ‹å‡†ç¡®æ€§
        action_obs_improvement = {
            0: -0.05,  # æ— åŠ¨ä½œï¼šè§‚æµ‹å‡†ç¡®æ€§ä¸‹é™
            1: 0.05,  # Mildï¼šè§‚æµ‹å‡†ç¡®æ€§æå‡
            2: 0.12,  # Intenseï¼šè§‚æµ‹å‡†ç¡®æ€§æ˜¾è‘—æå‡
        }

        if prev_action >= 3:
            # é«˜çº§åŠ¨ä½œï¼šé€’å¢è§‚æµ‹æ”¹å–„
            improvement = 0.12 + (prev_action - 2) * 0.03
            action_improvement = min(0.20, improvement)
        else:
            action_improvement = action_obs_improvement.get(prev_action, 0.0)

        # åº”ç”¨åŠ¨ä½œæ”¹å–„
        adjusted_accuracy = base_accuracy + action_improvement
        adjusted_noise = noise_level * (1.0 - abs(action_improvement))

        # ============================================
        # æ­¥éª¤4ï¼šè®¡ç®—è§‚æµ‹æ¦‚ç‡
        # ============================================

        if self.num_observations == 2:
            # 2çŠ¶æ€è§‚æµ‹

            # æ­£ç¡®è§‚æµ‹çš„æ¦‚ç‡
            correct_obs_prob = adjusted_accuracy

            # åº”ç”¨å™ªå£°
            correct_obs_prob = correct_obs_prob * (1 - adjusted_noise) + 0.5 * adjusted_noise

            # åº”ç”¨åå·®
            if current_state == 0:  # çœŸå®æœ€å·®çŠ¶æ€
                # æ‚²è§‚åå·®å¢åŠ æ­£ç¡®è¯†åˆ«æœ€å·®çŠ¶æ€çš„æ¦‚ç‡
                correct_obs_prob += observation_bias
            else:  # çœŸå®æœ€å¥½çŠ¶æ€
                # ä¹è§‚åå·®å¢åŠ æ­£ç¡®è¯†åˆ«æœ€å¥½çŠ¶æ€çš„æ¦‚ç‡
                correct_obs_prob -= observation_bias

            # é™åˆ¶èŒƒå›´
            correct_obs_prob = np.clip(correct_obs_prob, MIN_PROB, MAX_PROB)

            if current_state == 0:
                obs_probs = np.array([correct_obs_prob, 1.0 - correct_obs_prob])
            else:
                obs_probs = np.array([1.0 - correct_obs_prob, correct_obs_prob])

        elif self.num_observations == 3:
            # 3çŠ¶æ€è§‚æµ‹
            obs_probs = np.zeros(3)

            # åŸºç¡€æ­£ç¡®è§‚æµ‹æ¦‚ç‡
            correct_obs_prob = adjusted_accuracy

            # åº”ç”¨å™ªå£°ï¼ˆåˆ†æ•£åˆ°ç›¸é‚»çŠ¶æ€ï¼‰
            error_prob = adjusted_noise

            if current_state == 0:  # çœŸå®æœ€å·®çŠ¶æ€
                obs_probs[0] = correct_obs_prob
                obs_probs[1] = error_prob * 0.7
                obs_probs[2] = error_prob * 0.3

                # åº”ç”¨åå·®
                obs_probs[0] += observation_bias
                obs_probs[2] -= observation_bias

            elif current_state == 1:  # çœŸå®ä¸­ç­‰çŠ¶æ€
                obs_probs[0] = error_prob * 0.4
                obs_probs[1] = correct_obs_prob
                obs_probs[2] = error_prob * 0.4

            else:  # current_state == 2ï¼ŒçœŸå®æœ€å¥½çŠ¶æ€
                obs_probs[0] = error_prob * 0.3
                obs_probs[1] = error_prob * 0.7
                obs_probs[2] = correct_obs_prob

                # åº”ç”¨åå·®
                obs_probs[2] -= observation_bias
                obs_probs[0] += observation_bias

        else:  # num_observations >= 4
            # å¤šçŠ¶æ€è§‚æµ‹ï¼šåŸºäºè·ç¦»çš„æ··æ·†çŸ©é˜µ
            obs_probs = np.zeros(self.num_observations)

            for obs in range(self.num_observations):
                distance = abs(obs - current_state)

                if distance == 0:
                    # æ­£ç¡®è§‚æµ‹
                    obs_probs[obs] = adjusted_accuracy
                elif distance == 1:
                    # ç›¸é‚»çŠ¶æ€
                    obs_probs[obs] = adjusted_noise * 0.4
                elif distance == 2:
                    # è·ç¦»2
                    obs_probs[obs] = adjusted_noise * 0.2
                else:
                    # æ›´è¿œ
                    obs_probs[obs] = adjusted_noise * 0.1 / (distance - 1)

        # ============================================
        # æ­¥éª¤5ï¼šå½’ä¸€åŒ–å’ŒéªŒè¯
        # ============================================
        obs_probs = np.clip(obs_probs, MIN_PROB, MAX_PROB)

        # å½’ä¸€åŒ–
        prob_sum = np.sum(obs_probs)
        if prob_sum > 0:
            obs_probs = obs_probs / prob_sum
        else:
            obs_probs = np.ones(self.num_observations) / self.num_observations

        # ç²¾ç¡®åˆ°å°æ•°ç‚¹åä¸€ä½
        obs_probs = np.round(obs_probs, 1)

        # æœ€ç»ˆå½’ä¸€åŒ–æ£€æŸ¥
        final_sum = np.sum(obs_probs)
        if not np.isclose(final_sum, 1.0, atol=0.05):
            diff = 1.0 - final_sum
            max_idx = np.argmax(obs_probs)
            obs_probs[max_idx] += diff
            obs_probs = np.clip(obs_probs, MIN_PROB, MAX_PROB)
            obs_probs = obs_probs / np.sum(obs_probs)
            obs_probs = np.round(obs_probs, 1)

        return obs_probs

    def _validate_observation_matrix(self, observation_matrix, node):
        """éªŒè¯è§‚å¯ŸçŸ©é˜µçš„æœ‰æ•ˆæ€§"""
        print(f"ğŸ‘ï¸ éªŒè¯èŠ‚ç‚¹ {node} çš„è§‚æµ‹æ¦‚ç‡çŸ©é˜µ...")

        for s in range(self.num_states):
            for a in range(min(3, self.num_actions)):  # åªéªŒè¯å‰3ä¸ªåŠ¨ä½œ
                probs = observation_matrix[s, a, :]
                prob_sum = np.sum(probs)

                if not np.isclose(prob_sum, 1.0, rtol=1e-2):
                    print(f"    âš ï¸  çŠ¶æ€ {s}, å‰ä¸€åŠ¨ä½œ {a} - è§‚æµ‹æ¦‚ç‡å’Œ: {prob_sum:.3f}")

                if np.any(probs < 0):
                    print(f"    âš ï¸  çŠ¶æ€ {s}, å‰ä¸€åŠ¨ä½œ {a} - å­˜åœ¨è´Ÿè§‚æµ‹æ¦‚ç‡")

    def export_pomdp_parameters_to_excel(self, filename=None):
        """
        å°†POMDPå‚æ•°å¯¼å‡ºåˆ°Excelæ–‡ä»¶
        """
        if filename is None:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"Enhanced_POMDP_Parameters_{timestamp}.xlsx"

        print(f"\nğŸ“Š Exporting Enhanced POMDP Parameters to Excel: {filename}")
        print("=" * 70)

        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # Sheet 1: æ¦‚è¿°å’Œå®šä¹‰
            self._create_overview_sheet(writer)

            # Sheet 2: çŠ¶æ€è½¬ç§»æ¦‚ç‡
            self._create_transition_probabilities_sheet(writer)

            # Sheet 3: è§‚å¯Ÿæ¦‚ç‡
            self._create_observation_probabilities_sheet(writer)

            # Sheet 4: çŸ©é˜µæ±‡æ€»
            self._create_matrix_summary_sheet(writer)

        print(f"âœ… Enhanced POMDP parameters exported to: {filename}")
        return filename

    def _create_overview_sheet(self, writer):
        """åˆ›å»ºæ¦‚è¿°å’Œå®šä¹‰sheet"""
        overview_data = [
            ['Enhanced POMDP Parameters for Supply Chain Resilience', ''],
            ['Version', 'Random Experiment - Parameterized Generation'],
            ['Parameters Source', 'All from main function config (no defaults)'],
            ['Generation Method', 'Parameterized formulas (no hardcoded values)'],
            ['', ''],
            ['Model Configuration', ''],
            ['Number of Nodes', self.num_nodes],
            ['Number of Layers', self.layer_info.get('num_layers', 'N/A')],
            ['Number of States |R_k^t|', self.num_states],
            ['Number of Actions |A_k^t|', self.num_actions],
            ['Number of Observations |O_k^t|', self.num_observations],
            ['', ''],
            ['State Space Definitions (R_k^t)', ''],
        ]

        # æ·»åŠ çŠ¶æ€å®šä¹‰
        for state_id, description in self.state_definitions.items():
            overview_data.append([f'State {state_id}', description])

        overview_data.extend([
            ['', ''],
            ['Action Space Definitions (A_k^t)', ''],
        ])

        # æ·»åŠ è¡ŒåŠ¨å®šä¹‰
        for action_id, description in self.action_definitions.items():
            overview_data.append([f'Action {action_id}', description])

        overview_data.extend([
            ['', ''],
            ['Observation Space Definitions (O_k^t)', ''],
        ])

        # æ·»åŠ è§‚å¯Ÿå®šä¹‰
        for obs_id, description in self.observation_definitions.items():
            overview_data.append([f'Observation {obs_id}', description])

        overview_data.extend([
            ['', ''],
            ['Network Structure', ''],
            ['Network Type', self.layer_info.get('network_type', 'UNKNOWN')],
            ['Total Nodes', self.num_nodes],
            ['Nodes per Layer', str(self.layer_info.get('nodes_per_layer', 'N/A'))],
            ['', ''],
            ['Properties', ''],
            ['Time-Invariant Transitions', 'Yes - P(r^{t+1}|r^t,a^t) same for all periods'],
            ['Time-Invariant Observations', 'Yes - P(o^t|r^t,a^{t-1}) same for all periods'],
            ['Parameter Generation', 'Fully parameterized - no hardcoded values'],
            ['Node Differentiation', 'Hash-based node-specific factors'],
            ['Random Seed', self.seed],
        ])

        overview_df = pd.DataFrame(overview_data, columns=['Parameter', 'Description'])
        overview_df.to_excel(writer, sheet_name='Enhanced_Overview', index=False, header=False)

    def _create_transition_probabilities_sheet(self, writer):
        """åˆ›å»ºçŠ¶æ€è½¬ç§»æ¦‚ç‡sheet"""
        transition_data = []

        # åŠ¨æ€ç”Ÿæˆè¡¨å¤´
        header = ['Node_ID', 'Node_Type', 'Current_State', 'Action']
        for i in range(self.num_states):
            header.append(f'Next_State_{i}')
        transition_data.append(header)

        # æ•°æ®è¡Œ
        for node in range(self.num_nodes):
            node_type, _ = self._get_node_characteristics(node)
            transition_matrix = self.transition_probabilities[node]

            for current_state in range(self.num_states):
                for action in range(self.num_actions):
                    row = [
                        node,
                        node_type,
                        current_state,
                        action
                    ]

                    # æ·»åŠ è½¬ç§»æ¦‚ç‡
                    for next_state in range(self.num_states):
                        prob = transition_matrix[current_state, action, next_state]
                        row.append(f"{prob:.6f}")

                    transition_data.append(row)

        transition_df = pd.DataFrame(transition_data[1:], columns=transition_data[0])
        transition_df.to_excel(writer, sheet_name='Enhanced_Transitions', index=False)

    def _create_observation_probabilities_sheet(self, writer):
        """åˆ›å»ºè§‚å¯Ÿæ¦‚ç‡sheet"""
        observation_data = []

        # åŠ¨æ€ç”Ÿæˆè¡¨å¤´
        header = ['Node_ID', 'Node_Type', 'Current_State', 'Prev_Action']
        for i in range(self.num_observations):
            header.append(f'Obs_{i}')
        observation_data.append(header)

        # æ•°æ®è¡Œ
        for node in range(self.num_nodes):
            node_type, _ = self._get_node_characteristics(node)
            observation_matrix = self.observation_probabilities[node]

            for current_state in range(self.num_states):
                for prev_action in range(self.num_actions):
                    row = [
                        node,
                        node_type,
                        current_state,
                        prev_action
                    ]

                    # æ·»åŠ è§‚å¯Ÿæ¦‚ç‡
                    for obs in range(self.num_observations):
                        prob = observation_matrix[current_state, prev_action, obs]
                        row.append(f"{prob:.6f}")

                    observation_data.append(row)

        observation_df = pd.DataFrame(observation_data[1:], columns=observation_data[0])
        observation_df.to_excel(writer, sheet_name='Enhanced_Observations', index=False)

    def _create_matrix_summary_sheet(self, writer):
        """åˆ›å»ºçŸ©é˜µæ±‡æ€»sheet"""
        summary_data = [
            ['Enhanced POMDP Parameters Summary', ''],
            ['Version', 'Random Experiment - Parameterized'],
            ['', ''],
            ['Matrix Dimensions', ''],
            ['Transition Matrix per Node', f'{self.num_states} Ã— {self.num_actions} Ã— {self.num_states}'],
            ['Observation Matrix per Node', f'{self.num_states} Ã— {self.num_actions} Ã— {self.num_observations}'],
            ['Total Transition Parameters', self.num_nodes * self.num_states * self.num_actions * self.num_states],
            ['Total Observation Parameters',
             self.num_nodes * self.num_states * self.num_actions * self.num_observations],
            ['', ''],
            ['Configuration', ''],
            ['num_nodes', self.num_nodes],
            ['num_states from main config', self.num_states],
            ['num_actions from main config', self.num_actions],
            ['num_observations', self.num_observations],
            ['Random Seed', self.seed],
            ['', ''],
            ['Validation Results', ''],
        ]

        # æ·»åŠ éªŒè¯ç»Ÿè®¡
        total_transition_errors = 0
        total_observation_errors = 0

        for node in range(self.num_nodes):
            trans_matrix = self.transition_probabilities[node]
            for s in range(self.num_states):
                for a in range(self.num_actions):
                    if not np.isclose(np.sum(trans_matrix[s, a, :]), 1.0, rtol=1e-5):
                        total_transition_errors += 1

            obs_matrix = self.observation_probabilities[node]
            for s in range(self.num_states):
                for a in range(self.num_actions):
                    if not np.isclose(np.sum(obs_matrix[s, a, :]), 1.0, rtol=1e-5):
                        total_observation_errors += 1

        summary_data.extend([
            ['Transition Probability Errors', total_transition_errors],
            ['Observation Probability Errors', total_observation_errors],
            ['Overall Validation Status',
             'PASSED' if (total_transition_errors + total_observation_errors) == 0 else 'WARNING'],
        ])

        summary_df = pd.DataFrame(summary_data, columns=['Metric', 'Value'])
        summary_df.to_excel(writer, sheet_name='Enhanced_Summary', index=False, header=False)

    def generate_complete_pomdp_parameters(self, export_excel=True, filename=None):
        """
        ç”Ÿæˆå®Œæ•´çš„POMDPå‚æ•°
        æ‰€æœ‰å…³é”®å‚æ•°éƒ½æ¥è‡ªä¸»å‡½æ•°config

        Returns:
            tuple: (pomdp_parameterså­—å…¸, excelæ–‡ä»¶è·¯å¾„)
        """
        print("ğŸ¯ GENERATING COMPLETE ENHANCED POMDP PARAMETERS")
        print("   ğŸ”§ Random Experiment Version - Parameterized Generation")
        print("   All critical parameters from main function config (no defaults)")
        print("=" * 80)

        # ç”Ÿæˆè½¬ç§»æ¦‚ç‡
        transition_probs = self.generate_transition_probabilities()

        # ç”Ÿæˆè§‚å¯Ÿæ¦‚ç‡
        observation_probs = self.generate_observation_probabilities()

        # ç»„ç»‡ç»“æœ
        pomdp_parameters = {
            'configuration': {
                'num_nodes': self.num_nodes,
                'num_states': self.num_states,
                'num_actions': self.num_actions,
                'num_observations': self.num_observations,
                'state_definitions': self.state_definitions,
                'action_definitions': self.action_definitions,
                'observation_definitions': self.observation_definitions,
                'parameter_source': 'All from main function config',
                'version': 'Random Experiment - Parameterized',
                'generation_method': 'Hash-based parameterized formulas',
                'seed': self.seed
            },
            'transition_probabilities': transition_probs,
            'observation_probabilities': observation_probs,
            'network_info': {
                'num_nodes': self.num_nodes,
                'num_layers': self.layer_info.get('num_layers', 'N/A'),
                'nodes_per_layer': self.layer_info.get('nodes_per_layer', 'N/A'),
                'network_type': self.layer_info.get('network_type', 'UNKNOWN'),
                'network_structure': self.network.tolist()
            }
        }

        # å¯¼å‡ºåˆ°Excel
        excel_file = None
        if export_excel:
            excel_file = self.export_pomdp_parameters_to_excel(filename)

        print(f"\nğŸ‰ Enhanced POMDP parameters generation completed!")
        print(f"ğŸ“‹ Generated parameters for {self.num_nodes} nodes")
        print(f"ğŸ”„ Transition matrices: {self.num_states}Ã—{self.num_actions}Ã—{self.num_states} each")
        print(f"ğŸ‘ï¸  Observation matrices: {self.num_states}Ã—{self.num_actions}Ã—{self.num_observations} each")
        if excel_file:
            print(f"ğŸ“Š Excel export: {excel_file}")

        return pomdp_parameters, excel_file


def main():
    """
    ä¸»å‡½æ•°æ¼”ç¤º - ä½¿ç”¨R1_network_generate4ï¼ˆæ”¯æŒå¤šå±‚éšæœºç½‘ç»œï¼‰
    æ‰€æœ‰å‚æ•°éƒ½å¿…é¡»æ˜¾å¼ä¼ å…¥

    Current Date and Time (UTC): 2025-10-28 12:48:41
    Current User's Login: dyy21zyy
    """
    print("ğŸš€ ENHANCED POMDP PARAMETERS GENERATOR FOR SUPPLY CHAIN RESILIENCE")
    print("   Compatible with R1_network_generate4.py (multi-layer random networks)")
    print("   ğŸ”§ Random Experiment Version - No Hardcoded Values")
    print("=" * 80)

    # æ¨¡æ‹Ÿä¸»å‡½æ•°çš„é…ç½®å‚æ•°ï¼ˆæ‰€æœ‰å‚æ•°å¿…é¡»æ˜¾å¼æŒ‡å®šï¼‰
    main_config = {
        'total_nodes': 15,  # ğŸ”§ ä½¿ç”¨æ€»èŠ‚ç‚¹æ•°
        'num_layers': 4,  # ğŸ”§ 4å±‚ç½‘ç»œ
        'num_periods': 5,
        'num_states': 3,  # ğŸ”§ æµ‹è¯•3çŠ¶æ€
        'num_actions': 3,
        'connection_density': 0.7,
        'seed': 42
    }

    print(f"\nğŸ“‹ Main Function Configuration (all explicit, no defaults):")
    for key, value in main_config.items():
        print(f"   {key}: {value}")

    # ç”Ÿæˆä¾›åº”é“¾ç½‘ç»œï¼ˆä½¿ç”¨R1_network_generate4ï¼‰
    print(f"\nğŸ­ Generating Supply Chain Network using R1_network_generate4...")
    network_data = generate_supply_chain_network(
        total_nodes=main_config['total_nodes'],  # ğŸ”§ ä¿®æ”¹ç‚¹
        num_layers=main_config['num_layers'],  # ğŸ”§ ä¿®æ”¹ç‚¹
        num_periods=main_config['num_periods'],
        num_states=main_config['num_states'],
        connection_density=main_config['connection_density'],
        seed=main_config['seed'],
        network_type='random',  # ğŸ”§ ä¿®æ”¹ç‚¹
        verbose=False
    )

    # åˆ›å»ºPOMDPå‚æ•°ç”Ÿæˆå™¨
    print(f"\nğŸ”§ Initializing Enhanced POMDP Parameters Generator...")
    pomdp_generator = POMDPParametersGenerator(
        network_data=network_data,
        num_states=main_config['num_states'],
        num_actions=main_config['num_actions'],
        seed=main_config['seed']
    )

    # ç”Ÿæˆå®Œæ•´çš„POMDPå‚æ•°
    print(f"\nğŸ”§ Generating Enhanced POMDP Parameters...")
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    excel_filename = f"Enhanced_SupplyChain_POMDP_Random_{timestamp}.xlsx"

    pomdp_params, excel_file = pomdp_generator.generate_complete_pomdp_parameters(
        export_excel=True,
        filename=excel_filename
    )

    # æ˜¾ç¤ºä¸€ä¸ªèŠ‚ç‚¹çš„è½¬ç§»æ¦‚ç‡ç¤ºä¾‹
    sample_node = 0
    sample_transition = pomdp_params['transition_probabilities'][sample_node]

    print(f"\nğŸ” Transition Probabilities for Node {sample_node}:")
    print("P(next_state | current_state, action):")

    for current_state in range(min(2, pomdp_generator.num_states)):
        for action in range(min(3, pomdp_generator.num_actions)):
            probs = sample_transition[current_state, action, :]
            state_desc = pomdp_generator.state_definitions[current_state]
            action_desc = pomdp_generator.action_definitions[action]

            print(f"  Current: {current_state}({state_desc[:10]}...), Action: {action}({action_desc[:15]}...)")
            print(f"    â†’ {[f'{p:.3f}' for p in probs]}")

    return pomdp_generator, pomdp_params, excel_file


if __name__ == "__main__":
    try:
        generator, parameters, excel_file = main()
        print(f"\nâœ… Success!")
        print(f"ğŸ“ Excel file: {excel_file}")
        print(f"ğŸ”§ Fully compatible with random experiment framework!")
    except Exception as e:
        import traceback

        print(f"\nâŒ Error occurred: {e}")
        print("Full traceback:")
        traceback.print_exc()