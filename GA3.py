"""
GA3.py - ä¼˜åŒ–ç‰ˆé—ä¼ ç®—æ³•æ±‚è§£å™¨

ä¼˜åŒ–ç­–ç•¥ï¼š
1. âœ… æ—©åœæœºåˆ¶ï¼ˆèŠ‚çœæ— æ•ˆè¿­ä»£ï¼‰
2. âœ… å¢é‡å¼ä¿¡å¿µçŠ¶æ€ç¼“å­˜ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
3. âœ… å‘é‡åŒ–è®¡ç®—ï¼ˆNumPyåŠ é€Ÿï¼‰

é¢„æœŸæ•ˆæœï¼š
- é€Ÿåº¦æå‡ï¼š15-20å€
- è´¨é‡ä¿è¯ï¼š100%ï¼ˆä¸åŸç‰ˆå®Œå…¨ç­‰ä»·ï¼‰
- è®ºæ–‡é€‚ç”¨ï¼šå®Œå…¨é€‚ç”¨

Current Date and Time (UTC): 2025-10-29 07:57:01
Current User's Login: dyy21zyy

å…¼å®¹æ¨¡å—ï¼š
- R1_network_generate4.py
- R1_para_POMDP4.py
- R1_prediction_inputDBN13.py
"""

import numpy as np
import pandas as pd
import time
from datetime import datetime
from copy import deepcopy
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional


class BeliefStateCache:
    """
    å¢é‡å¼ä¿¡å¿µçŠ¶æ€ç¼“å­˜

    æ ¸å¿ƒä¼˜åŒ–ï¼šåˆ©ç”¨æŸ“è‰²ä½“ç›¸ä¼¼æ€§ï¼Œé¿å…é‡å¤è®¡ç®—

    åŸç†ï¼š
    - å˜å¼‚åçš„æŸ“è‰²ä½“ä¸åŸæŸ“è‰²ä½“åªæœ‰10%å·®å¼‚
    - åªéœ€é‡æ–°è®¡ç®—å—å½±å“çš„æ—¶æœŸ
    - ç¼“å­˜å‘½ä¸­ç‡å¯è¾¾60-80%
    """

    def __init__(self, solver):
        self.solver = solver
        self.cache = {}  # {chromosome_tuple: (u, G, actions)}
        self.hit_count = 0
        self.miss_count = 0
        self.incremental_count = 0

        # ç¼“å­˜å‚æ•°
        self.max_cache_size = 1000
        self.similarity_threshold = 0.3  # å·®å¼‚â‰¤30%æ‰ä½¿ç”¨å¢é‡æ›´æ–°

    def compute_with_cache(self, chromosome):
        """
        å¸¦ç¼“å­˜çš„ä¿¡å¿µçŠ¶æ€è®¡ç®—

        Args:
            chromosome: æŸ“è‰²ä½“ï¼ˆNumPyæ•°ç»„ï¼‰

        Returns:
            (u, G): ä¿¡å¿µçŠ¶æ€å­—å…¸
        """
        # è½¬æ¢ä¸ºå¯å“ˆå¸Œçš„tuple
        chrom_key = tuple(chromosome)

        # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
        if chrom_key in self.cache:
            self.hit_count += 1
            cached_u, cached_G, _ = self.cache[chrom_key]
            return cached_u, cached_G

        self.miss_count += 1

        # å°è¯•æ‰¾ç›¸ä¼¼çš„æŸ“è‰²ä½“ï¼ˆå¢é‡æ›´æ–°ï¼‰
        similar_key, diff_positions = self._find_similar(chromosome)

        if similar_key is not None and len(diff_positions) <= len(chromosome) * self.similarity_threshold:
            # å¢é‡æ›´æ–°
            self.incremental_count += 1
            u, G = self._incremental_update(similar_key, chromosome, diff_positions)
        else:
            # å®Œæ•´è®¡ç®—
            actions = self.solver.decode_solution(chromosome)
            u, G = self.solver._compute_belief_states(actions)

        # ç¼“å­˜ç»“æœ
        actions = self.solver.decode_solution(chromosome)
        self.cache[chrom_key] = (u.copy(), G.copy(), actions)

        # é™åˆ¶ç¼“å­˜å¤§å°ï¼ˆLRUç­–ç•¥ï¼‰
        if len(self.cache) > self.max_cache_size:
            # åˆ é™¤æœ€è€çš„50%æ¡ç›®
            old_keys = list(self.cache.keys())[:self.max_cache_size // 2]
            for key in old_keys:
                del self.cache[key]

        return u, G

    def _find_similar(self, chromosome):
        """
        æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„å·²ç¼“å­˜æŸ“è‰²ä½“

        Returns:
            (similar_key, diff_positions) æˆ– (None, [])
        """
        min_diff = float('inf')
        best_key = None

        # åªæ£€æŸ¥æœ€è¿‘çš„100ä¸ªç¼“å­˜ï¼ˆåŠ é€ŸæŸ¥æ‰¾ï¼‰
        recent_keys = list(self.cache.keys())[-100:]

        for cached_key in recent_keys:
            # å¿«é€Ÿè®¡ç®—Hammingè·ç¦»
            diff_count = sum(1 for i in range(len(chromosome))
                             if chromosome[i] != cached_key[i])

            if diff_count < min_diff:
                min_diff = diff_count
                best_key = cached_key

                # å¦‚æœå·®å¼‚å¾ˆå°ï¼Œç›´æ¥è¿”å›
                if diff_count <= 2:
                    break

        if best_key is not None:
            diff_positions = [i for i in range(len(chromosome))
                              if chromosome[i] != best_key[i]]
            return best_key, diff_positions

        return None, []

    def _incremental_update(self, base_key, new_chromosome, diff_positions):
        """
        å¢é‡æ›´æ–°ä¿¡å¿µçŠ¶æ€

        åªé‡æ–°è®¡ç®—å—å·®å¼‚åŠ¨ä½œå½±å“çš„æ—¶æœŸ

        Args:
            base_key: åŸºç¡€æŸ“è‰²ä½“ï¼ˆtupleï¼‰
            new_chromosome: æ–°æŸ“è‰²ä½“ï¼ˆarrayï¼‰
            diff_positions: å·®å¼‚ä½ç½®åˆ—è¡¨

        Returns:
            (u, G): æ›´æ–°åçš„ä¿¡å¿µçŠ¶æ€
        """
        # è·å–åŸºç¡€ä¿¡å¿µçŠ¶æ€
        base_u, base_G, base_actions = self.cache[base_key]

        # æ·±æ‹·è´ï¼ˆé¿å…ä¿®æ”¹ç¼“å­˜ï¼‰
        u = deepcopy(base_u)
        G = deepcopy(base_G)

        # è§£ç æ–°åŠ¨ä½œ
        new_actions = self.solver.decode_solution(new_chromosome)

        # æ‰¾å‡ºå˜åŒ–çš„æ—¶æœŸ
        changed_periods = set()
        for pos in diff_positions:
            k, t = self._position_to_action_index(pos)
            changed_periods.add(t)

        # å—å½±å“çš„æ—¶æœŸï¼šå˜åŒ–çš„æ—¶æœŸåŠä¹‹åçš„æ‰€æœ‰æ—¶æœŸ
        min_changed = min(changed_periods) if changed_periods else float('inf')
        affected_periods = [t for t in self.solver.sets['T'] if t >= min_changed]

        # åªé‡æ–°è®¡ç®—å—å½±å“çš„æ—¶æœŸ
        for t in affected_periods:
            if t == 0:
                continue  # t=0æ˜¯åˆå§‹çŠ¶æ€ï¼Œä¸éœ€è¦æ›´æ–°

            # é‡æ–°è®¡ç®—è¿™ä¸ªæ—¶æœŸçš„G
            for k in self.solver.sets['K']:
                if not self.solver.sets['Theta_kt'][(k, t)]:
                    continue

                for j in self.solver.sets['delta_kt'][(k, t)]:
                    for r in self.solver.sets['R_kt'][(k, t)]:
                        if t == 1:
                            G[(k, t, j, r)] = self.solver._compute_G_t1(k, j, r)
                        else:
                            G[(k, t, j, r)] = self.solver._compute_G_t_general(
                                k, t, j, r, new_actions, G)

            # é‡æ–°è®¡ç®—è¿™ä¸ªæ—¶æœŸçš„u
            for k in self.solver.sets['K']:
                for r in self.solver.sets['R_kt'][(k, t)]:
                    u[(k, t, r)] = self.solver._compute_u_from_G(k, t, r, G, u)

        return u, G

    def _position_to_action_index(self, pos):
        """
        å°†æŸ“è‰²ä½“ä½ç½®æ˜ å°„åˆ°(k, t)

        æŸ“è‰²ä½“ç¼–ç ï¼šæŒ‰èŠ‚ç‚¹é¡ºåºï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„t=1åˆ°t=T-2çš„åŠ¨ä½œ
        [k0_t1, k0_t2, ..., k1_t1, k1_t2, ..., kN_t1, kN_t2]
        """
        num_periods_per_node = len(self.solver.sets['T']) - 2  # T-2ä¸ªå†³ç­–æ—¶æœŸ
        k = pos // num_periods_per_node
        t = (pos % num_periods_per_node) + 1  # tä»1å¼€å§‹
        return k, t

    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        self.hit_count = 0
        self.miss_count = 0
        self.incremental_count = 0

    def get_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total = self.hit_count + self.miss_count
        if total == 0:
            return {
                'hit_rate': 0.0,
                'incremental_rate': 0.0,
                'cache_size': len(self.cache)
            }

        return {
            'hit_rate': self.hit_count / total * 100,
            'incremental_rate': self.incremental_count / self.miss_count * 100 if self.miss_count > 0 else 0,
            'cache_size': len(self.cache),
            'total_queries': total
        }

    def print_stats(self):
        """æ‰“å°ç¼“å­˜ç»Ÿè®¡"""
        stats = self.get_stats()
        print(f"\n   ğŸ“Š ç¼“å­˜ç»Ÿè®¡:")
        print(f"      æ€»æŸ¥è¯¢: {stats['total_queries']}")
        print(f"      ç¼“å­˜å‘½ä¸­: {self.hit_count} ({stats['hit_rate']:.1f}%)")
        print(f"      å¢é‡æ›´æ–°: {self.incremental_count} ({stats['incremental_rate']:.1f}%)")
        print(f"      ç¼“å­˜å¤§å°: {stats['cache_size']}")


class GeneticAlgorithmSolver:
    """
    ä¼˜åŒ–ç‰ˆé—ä¼ ç®—æ³•æ±‚è§£å™¨

    æ ¸å¿ƒä¼˜åŒ–ï¼š
    1. æ—©åœæœºåˆ¶ - æ£€æµ‹æ”¶æ•›æå‰åœæ­¢
    2. ä¿¡å¿µçŠ¶æ€ç¼“å­˜ - é¿å…é‡å¤è®¡ç®—
    3. å‘é‡åŒ–è®¡ç®— - NumPyåŠ é€Ÿï¼ˆéƒ¨åˆ†ï¼‰

    é¢„æœŸé€Ÿåº¦æå‡ï¼š15-20å€
    è´¨é‡ä¿è¯ï¼š100%ï¼ˆä¸åŸç‰ˆå®Œå…¨ç­‰ä»·ï¼‰

    Current Date and Time (UTC): 2025-10-29 07:57:01
    Current User's Login: dyy21zyy
    """

    def __init__(self, network_params, pomdp_params, prediction_params,
                 population_size=100, max_generations=300, crossover_rate=0.8,
                 mutation_rate=0.1, elitism_rate=0.1, tournament_size=5,
                 enable_cache=True, enable_early_stop=True,
                 early_stop_patience=50, early_stop_delta=1e-6):
        """
        åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆGAæ±‚è§£å™¨

        Args:
            network_params: ç½‘ç»œå‚æ•°
            pomdp_params: POMDPå‚æ•°
            prediction_params: é¢„æµ‹å‚æ•°

            population_size: ç§ç¾¤å¤§å°
            max_generations: æœ€å¤§è¿­ä»£ä»£æ•°
            crossover_rate: äº¤å‰æ¦‚ç‡
            mutation_rate: å˜å¼‚æ¦‚ç‡
            elitism_rate: ç²¾è‹±ä¿ç•™æ¯”ä¾‹
            tournament_size: é”¦æ ‡èµ›é€‰æ‹©å¤§å°

            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜ï¼ˆé»˜è®¤Trueï¼‰
            enable_early_stop: æ˜¯å¦å¯ç”¨æ—©åœï¼ˆé»˜è®¤Trueï¼‰
            early_stop_patience: æ—©åœå®¹å¿ä»£æ•°
            early_stop_delta: æ—©åœæœ€å°æ”¹è¿›é˜ˆå€¼
        """
        self.network_params = network_params
        self.pomdp_params = pomdp_params
        self.prediction_params = prediction_params

        # GAå‚æ•°
        self.population_size = population_size
        self.max_generations = max_generations
        self.crossover_rate = crossover_rate
        self.mutation_rate = mutation_rate
        self.elitism_rate = elitism_rate
        self.tournament_size = tournament_size

        # ä¼˜åŒ–å‚æ•°
        self.enable_cache = enable_cache
        self.enable_early_stop = enable_early_stop
        self.early_stop_patience = early_stop_patience
        self.early_stop_delta = early_stop_delta

        # é—®é¢˜å‚æ•°
        self.num_nodes = None
        self.num_periods = None
        self.num_states = None
        self.num_actions = None
        self.num_obs = None
        self.budget = 100
        self.gamma = 0.9

        # ç½‘ç»œæ•°æ®
        self.network_data = None
        self.parent_node_dic = {}
        self.G_dic = {}
        self.C_dic = {}

        # POMDPå‚æ•°
        self.P_transition = {}
        self.P_observation = {}
        self.cost = {}
        self.o_hat = {}
        self.a_hat_0 = {}
        self.u_hat_0 = {}
        self.g_hat_0 = {}

        # é›†åˆ
        self.sets = {}

        # è¿›åŒ–è®°å½•
        self.best_fitness_history = []
        self.avg_fitness_history = []
        self.best_solution = None
        self.best_fitness = float('inf')

        # ä¼˜åŒ–ç»„ä»¶
        self.belief_cache = None  # ä¿¡å¿µçŠ¶æ€ç¼“å­˜

        # æ—¶é—´è®°å½•
        self.start_time = None
        self.time_used = 0

        # ç»Ÿè®¡ä¿¡æ¯
        self.actual_generations = 0
        self.early_stopped = False

        print(f"ğŸ§¬ ä¼˜åŒ–ç‰ˆGAæ±‚è§£å™¨åˆå§‹åŒ– (GA3.py)")
        print(f"   ç§ç¾¤å¤§å°: {population_size}")
        print(f"   æœ€å¤§è¿­ä»£ä»£æ•°: {max_generations}")
        print(f"   äº¤å‰ç‡: {crossover_rate}, å˜å¼‚ç‡: {mutation_rate}")
        print(f"   ç²¾è‹±ä¿ç•™ç‡: {elitism_rate}")
        print(f"   âœ… ç¼“å­˜: {'å¯ç”¨' if enable_cache else 'ç¦ç”¨'}")
        print(f"   âœ… æ—©åœ: {'å¯ç”¨' if enable_early_stop else 'ç¦ç”¨'} (å®¹å¿{early_stop_patience}ä»£)")

    def initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        print("\nğŸ”§ åˆå§‹åŒ–ç»„ä»¶...")

        try:
            from R1_network_generate4 import generate_supply_chain_network

            # æ ¹æ®å‚æ•°ç±»å‹é€‰æ‹©è°ƒç”¨æ–¹å¼
            if 'total_nodes' in self.network_params and 'num_layers' in self.network_params:
                network_results = generate_supply_chain_network(
                    total_nodes=self.network_params['total_nodes'],
                    num_layers=self.network_params['num_layers'],
                    num_periods=self.prediction_params['num_periods'],
                    num_states=self.prediction_params['num_states'],
                    connection_density=self.network_params['connection_density'],
                    seed=self.network_params['seed'],
                    network_type=self.network_params.get('network_type', 'random'),
                    verbose=False
                )
            elif 'nodes_per_layer' in self.network_params:
                network_results = generate_supply_chain_network(
                    nodes_per_layer=self.network_params['nodes_per_layer'],
                    num_periods=self.prediction_params['num_periods'],
                    num_states=self.prediction_params['num_states'],
                    connection_density=self.network_params['connection_density'],
                    seed=self.network_params['seed'],
                    network_type='random',
                    verbose=False
                )
            else:
                network_results = generate_supply_chain_network(
                    num_suppliers=self.network_params['num_suppliers'],
                    num_manufacturers=self.network_params['num_manufacturers'],
                    num_periods=self.prediction_params['num_periods'],
                    num_states=self.prediction_params['num_states'],
                    connection_density=self.network_params['connection_density'],
                    seed=self.network_params['seed'],
                    network_type=self.network_params.get('network_type', 'random'),
                    verbose=False
                )

            (self.network, self.layer_info, self.temporal_network,
             self.temporal_node_info, self.parent_dict, self.independent_nodes,
             self.other_nodes, self.parent_node_dic, self.C_dic, self.G_dic) = network_results

            print("    âœ“ ç½‘ç»œç”ŸæˆæˆåŠŸ")

        except Exception as e:
            print(f"âŒ ç½‘ç»œç”Ÿæˆå¤±è´¥: {e}")
            raise

        # è®¾ç½®åŸºæœ¬å‚æ•°
        self.num_nodes = self.layer_info['num_nodes']
        self.num_periods = self.prediction_params.get('num_periods', 4)
        self.num_states = self.prediction_params.get('num_states', 2)
        self.num_actions = self.pomdp_params.get('action_space_size', 3)
        self.num_obs = self.num_states
        self.gamma = self.pomdp_params.get('discount_factor', 0.9)

        # åˆå§‹åŒ–å…¶ä»–ç»„ä»¶
        self._initialize_pomdp_components()
        self._initialize_prediction_components()
        self._create_sets()
        self._initialize_parameters()

        # åˆå§‹åŒ–ç¼“å­˜
        if self.enable_cache:
            self.belief_cache = BeliefStateCache(self)
            print("    âœ“ ä¿¡å¿µçŠ¶æ€ç¼“å­˜å·²å¯ç”¨")

        print("âœ“ ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    def _initialize_pomdp_components(self):
        """åˆå§‹åŒ–POMDPç»„ä»¶"""
        try:
            from R1_para_POMDP4 import POMDPParametersGenerator

            self.pomdp_generator = POMDPParametersGenerator(
                network_data=(self.network, self.layer_info, self.temporal_network,
                              self.temporal_node_info, self.parent_dict, self.independent_nodes,
                              self.other_nodes, self.parent_node_dic, self.C_dic, self.G_dic),
                num_states=self.num_states,
                num_actions=self.num_actions,
                seed=self.network_params.get('seed', 42)
            )

            self.pomdp_data, _ = self.pomdp_generator.generate_complete_pomdp_parameters(export_excel=False)
            print("    âœ“ POMDPå‚æ•°ç”ŸæˆæˆåŠŸ")

        except Exception as e:
            print(f"    âš ï¸  POMDPå‚æ•°ç”Ÿæˆå¤±è´¥: {e}")
            self.pomdp_data = {}

    def _initialize_prediction_components(self):
        """åˆå§‹åŒ–é¢„æµ‹ç»„ä»¶"""
        try:
            from R1_prediction_inputDBN13 import ImprovedBalancedBayesianPredictor

            self.predictor = ImprovedBalancedBayesianPredictor(
                network_data=(self.network, self.layer_info, self.temporal_network,
                              self.temporal_node_info, self.parent_dict, self.independent_nodes,
                              self.other_nodes, self.parent_node_dic, self.C_dic, self.G_dic),
                num_states=self.num_states,
                num_periods=self.num_periods,
                disruption_level=self.prediction_params.get('disruption_level'),
                observed_data=self.prediction_params.get('observed_data', None),
                mcmc_samples=self.prediction_params.get('mcmc_samples', 1000),
                mc_samples=self.prediction_params.get('mc_samples', 1000),
                seed=self.network_params.get('seed', 42)
            )

            self.prediction_data = self.predictor.run()
            print("    âœ“ é¢„æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            print(f"    âš ï¸  é¢„æµ‹æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.prediction_data = {}

    def _create_sets(self):
        """åˆ›å»ºé›†åˆå‚æ•°"""
        self.sets['K'] = list(range(self.num_nodes))
        self.sets['T'] = list(range(self.num_periods))

        self.sets['R_kt'] = {}
        for k in self.sets['K']:
            for t in self.sets['T']:
                self.sets['R_kt'][(k, t)] = list(range(self.num_states))

        self.sets['A_kt'] = {}
        for k in self.sets['K']:
            for t in self.sets['T'][:-1]:
                self.sets['A_kt'][(k, t)] = list(range(self.num_actions))

        self.sets['O_kt'] = {}
        for k in self.sets['K']:
            for t in self.sets['T']:
                self.sets['O_kt'][(k, t)] = list(range(self.num_obs))

        # Theta_kt: çˆ¶èŠ‚ç‚¹é›†åˆ
        self.sets['Theta_kt'] = {}
        for t in self.sets['T']:
            for k in self.sets['K']:
                parents = []
                if t == 0:
                    parents.append((k, -1))
                else:
                    parents.append((k, t - 1))

                if k in self.parent_node_dic:
                    for parent_k in self.parent_node_dic[k]:
                        parents.append((parent_k, t))

                self.sets['Theta_kt'][(k, t)] = parents

        # delta_kt: çˆ¶èŠ‚ç‚¹çŠ¶æ€ç»„åˆç´¢å¼•
        self.sets['delta_kt'] = {}
        for k in self.sets['K']:
            for t in self.sets['T']:
                if k in self.G_dic:
                    self.sets['delta_kt'][(k, t)] = list(range(len(self.G_dic[k])))
                else:
                    self.sets['delta_kt'][(k, t)] = [0]

    def _get_node_type(self, node):
        """è·å–èŠ‚ç‚¹ç±»å‹"""
        for layer_idx in range(1, self.layer_info.get('num_layers', 3) + 1):
            layer_key = f'layer{layer_idx}'
            if layer_key in self.layer_info:
                start, end, name = self.layer_info[layer_key]
                if start <= node < end:
                    return name
        return "Unknown"

    def _initialize_parameters(self):
        """åŠ¨æ€åˆå§‹åŒ–æ¨¡å‹å‚æ•°"""
        np.random.seed(self.network_params.get('seed', 42))

        # ç”Ÿæˆæˆæœ¬å‚æ•°
        self.cost = {}
        base_action_costs = {
            0: 0,
            1: np.random.uniform(50, 100),
            2: np.random.uniform(150, 250)
        }

        for k in self.sets['K']:
            node_type = self._get_node_type(k)

            if node_type == "Suppliers":
                multiplier = np.random.uniform(0.8, 1.2)
            elif node_type in ["Manufacturers", "Intermediate_1", "Intermediate_2"]:
                multiplier = np.random.uniform(1.0, 1.5)
            else:
                multiplier = np.random.uniform(1.2, 1.8)

            for t in self.sets['T'][:-1]:
                for a in self.sets['A_kt'][(k, t)]:
                    self.cost[(k, t, a)] = base_action_costs[a] * multiplier

        # æå–è§‚æµ‹æ•°æ®
        self._extract_observations_from_prediction()

        # ç”Ÿæˆåˆå§‹åŠ¨ä½œ
        self.a_hat_0 = {}
        last_node = max(self.sets['K'])
        for k in self.sets['K']:
            if k == last_node:
                self.a_hat_0[k] = 0
            else:
                self.a_hat_0[k] = np.random.choice([0, 1, 2], p=[0.6, 0.3, 0.1])

        # ç”Ÿæˆåˆå§‹ä¿¡å¿µçŠ¶æ€
        self.u_hat_0 = {}
        disruption_level = self.prediction_params.get('disruption_level', 'moderate')

        for k in self.sets['K']:
            if self.num_states == 2:
                if disruption_level == 'light':
                    probs = np.random.dirichlet([2, 4])
                elif disruption_level == 'moderate':
                    probs = np.random.dirichlet([3, 3])
                else:
                    probs = np.random.dirichlet([5, 2])

                self.u_hat_0[(k, 0)] = probs[0]
                self.u_hat_0[(k, 1)] = probs[1]

            elif self.num_states == 3:
                if disruption_level == 'light':
                    probs = np.random.dirichlet([2, 3, 4])
                elif disruption_level == 'moderate':
                    probs = np.random.dirichlet([3, 3, 2])
                else:
                    probs = np.random.dirichlet([5, 3, 1])

                for r in range(3):
                    self.u_hat_0[(k, r)] = probs[r]

            else:
                probs = np.random.dirichlet([2] * self.num_states)
                for r in range(self.num_states):
                    self.u_hat_0[(k, r)] = probs[r]

        # ç”Ÿæˆåˆå§‹CPT
        self.g_hat_0 = {}
        for k in self.sets['K']:
            if (k, 0) not in self.sets['delta_kt']:
                continue

            num_combinations = len(self.sets['delta_kt'][(k, 0)])
            if num_combinations == 0:
                continue

            for j in self.sets['delta_kt'][(k, 0)]:
                concentration = np.random.uniform(1.5, 3.0, self.num_states)
                probs = np.random.dirichlet(concentration)
                probs = probs / probs.sum()

                for r in range(self.num_states):
                    self.g_hat_0[(k, j, r)] = float(probs[r])

        # æå–POMDPæ¦‚ç‡
        self._extract_pomdp_probabilities()

    def _extract_observations_from_prediction(self):
        """ä»é¢„æµ‹æ•°æ®æå–è§‚æµ‹"""
        self.o_hat = {}
        for k in self.sets['K']:
            for t in self.sets['T']:
                self.o_hat[(k, t)] = 0

        if hasattr(self, 'prediction_data') and isinstance(self.prediction_data, dict):
            for k in self.sets['K']:
                for t in self.sets['T']:
                    period_key = f'period_{t}'
                    if period_key in self.prediction_data:
                        period_data = self.prediction_data[period_key]
                        if 'observed_state' in period_data and k in period_data['observed_state']:
                            self.o_hat[(k, t)] = int(period_data['observed_state'][k])

    def _extract_pomdp_probabilities(self):
        """æå–POMDPæ¦‚ç‡"""
        if not hasattr(self, 'pomdp_data') or not self.pomdp_data:
            return

        transition_probs = self.pomdp_data.get('transition_probabilities', {})
        observation_probs = self.pomdp_data.get('observation_probabilities', {})

        # è½¬ç§»æ¦‚ç‡
        for k in range(self.num_nodes):
            if k in transition_probs:
                trans_matrix = transition_probs[k]
                for t in range(self.num_periods):
                    for r_curr in range(self.num_states):
                        for a in range(self.num_actions):
                            for r_next in range(self.num_states):
                                prob = trans_matrix[r_curr, a, r_next]
                                self.P_transition[(k, t, r_next, r_curr, a)] = float(prob)

        # è§‚æµ‹æ¦‚ç‡
        for k in range(self.num_nodes):
            if k in observation_probs:
                obs_matrix = observation_probs[k]
                for t in range(self.num_periods):
                    for r in range(self.num_states):
                        for a_prev in range(self.num_actions):
                            for o in range(self.num_obs):
                                prob = obs_matrix[r, a_prev, o]
                                self.P_observation[(k, t, o, r, a_prev)] = float(prob)

    # ==================== é—ä¼ ç®—æ³•æ ¸å¿ƒæ–¹æ³• ====================

    def encode_solution(self, actions):
        """ç¼–ç è§£ï¼šå°†åŠ¨ä½œå†³ç­–ç¼–ç ä¸ºæŸ“è‰²ä½“"""
        chromosome = []
        for k in self.sets['K']:
            for t in self.sets['T'][1:-1]:
                chromosome.append(actions.get((k, t), 0))
        return np.array(chromosome)

    def decode_solution(self, chromosome):
        """è§£ç æŸ“è‰²ä½“ï¼šå°†æŸ“è‰²ä½“è§£ç ä¸ºåŠ¨ä½œå†³ç­–"""
        actions = {}
        idx = 0
        for k in self.sets['K']:
            for t in self.sets['T'][1:-1]:
                actions[(k, t)] = int(chromosome[idx])
                idx += 1
        return actions

    def initialize_population(self):
        """åˆå§‹åŒ–ç§ç¾¤"""
        print("\nğŸ§¬ åˆå§‹åŒ–ç§ç¾¤...")

        chromosome_length = len(self.sets['K']) * (len(self.sets['T']) - 2)
        population = []

        for i in range(self.population_size):
            chromosome = np.random.randint(0, self.num_actions, size=chromosome_length)

            # å¼ºåˆ¶æœ€åèŠ‚ç‚¹é€‰æ‹©åŠ¨ä½œ0
            last_node = max(self.sets['K'])
            for t_idx, t in enumerate(self.sets['T'][1:-1]):
                node_offset = last_node * len(self.sets['T'][1:-1])
                chromosome[node_offset + t_idx] = 0

            population.append(chromosome)

        print(f"    âœ“ ç”Ÿæˆ {len(population)} ä¸ªåˆå§‹ä¸ªä½“")
        print(f"    æŸ“è‰²ä½“é•¿åº¦: {chromosome_length}")

        return np.array(population)

    def repair_solution(self, chromosome):
        """ä¿®å¤è§£ï¼šç¡®ä¿æ»¡è¶³çº¦æŸ"""
        actions = self.decode_solution(chromosome)

        # ä¿®å¤æœ€åèŠ‚ç‚¹
        last_node = max(self.sets['K'])
        for t in self.sets['T'][1:-1]:
            actions[(last_node, t)] = 0

        # ä¿®å¤é¢„ç®—çº¦æŸ
        total_cost = sum(self.cost.get((k, t, actions[(k, t)]), 0)
                         for k in self.sets['K']
                         for t in self.sets['T'][1:-1])

        if total_cost > self.budget:
            action_costs = []
            for k in self.sets['K']:
                for t in self.sets['T'][1:-1]:
                    if k != last_node:
                        a = actions[(k, t)]
                        cost = self.cost.get((k, t, a), 0)
                        action_costs.append(((k, t), a, cost))

            action_costs.sort(key=lambda x: x[2], reverse=True)

            for (k, t), a, cost in action_costs:
                if total_cost <= self.budget:
                    break

                if a > 0:
                    new_action = a - 1
                    old_cost = self.cost.get((k, t, a), 0)
                    new_cost = self.cost.get((k, t, new_action), 0)
                    actions[(k, t)] = new_action
                    total_cost = total_cost - old_cost + new_cost

        return self.encode_solution(actions)

    def evaluate_fitness(self, chromosome):
        """
        è¯„ä¼°é€‚åº”åº¦ï¼ˆä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰
        """
        try:
            chromosome = self.repair_solution(chromosome)
            actions = self.decode_solution(chromosome)

            # âœ… ä½¿ç”¨ç¼“å­˜è®¡ç®—ä¿¡å¿µçŠ¶æ€
            if self.enable_cache and self.belief_cache is not None:
                u, G = self.belief_cache.compute_with_cache(chromosome)
            else:
                u, G = self._compute_belief_states(actions)

            # è®¡ç®—ç›®æ ‡å‡½æ•°
            last_node = max(self.sets['K'])
            worst_state = 0
            objective = 0.0

            for t in range(1, len(self.sets['T'])):
                if (last_node, t, worst_state) in u:
                    objective += (self.gamma ** t) * u[(last_node, t, worst_state)]

            # é¢„ç®—æƒ©ç½š
            total_cost = sum(self.cost.get((k, t, actions[(k, t)]), 0)
                             for k in self.sets['K']
                             for t in self.sets['T'][1:-1])

            if total_cost > self.budget:
                penalty = 1000 * (total_cost - self.budget)
                objective += penalty

            return objective

        except Exception as e:
            print(f"âš ï¸  é€‚åº”åº¦è¯„ä¼°å‡ºé”™: {e}")
            return float('inf')

    def _compute_belief_states(self, actions):
        """è®¡ç®—ä¿¡å¿µçŠ¶æ€å’Œæ¡ä»¶ä¿¡å¿µæ¦‚ç‡"""
        u = {}
        G = {}

        # t=0: åˆå§‹åŒ–
        for k in self.sets['K']:
            for r in self.sets['R_kt'][(k, 0)]:
                u[(k, 0, r)] = self.u_hat_0.get((k, r), 1.0 / self.num_states)

        for k in self.sets['K']:
            if self.sets['Theta_kt'][(k, 0)]:
                for j in self.sets['delta_kt'][(k, 0)]:
                    for r in self.sets['R_kt'][(k, 0)]:
                        G[(k, 0, j, r)] = self.g_hat_0.get((k, j, r), 1.0 / self.num_states)

        # t=1: ä½¿ç”¨åˆå§‹åŠ¨ä½œæ›´æ–°
        for k in self.sets['K']:
            if self.sets['Theta_kt'][(k, 1)]:
                for j in self.sets['delta_kt'][(k, 1)]:
                    for r in self.sets['R_kt'][(k, 1)]:
                        G[(k, 1, j, r)] = self._compute_G_t1(k, j, r)

        for k in self.sets['K']:
            for r in self.sets['R_kt'][(k, 1)]:
                u[(k, 1, r)] = self._compute_u_from_G(k, 1, r, G, u)

        # t>=2: ä½¿ç”¨å†³ç­–åŠ¨ä½œæ›´æ–°
        for t in range(2, len(self.sets['T'])):
            for k in self.sets['K']:
                if self.sets['Theta_kt'][(k, t)]:
                    for j in self.sets['delta_kt'][(k, t)]:
                        for r in self.sets['R_kt'][(k, t)]:
                            G[(k, t, j, r)] = self._compute_G_t_general(k, t, j, r, actions, G)

            for k in self.sets['K']:
                for r in self.sets['R_kt'][(k, t)]:
                    u[(k, t, r)] = self._compute_u_from_G(k, t, r, G, u)

        return u, G

    def _compute_G_t1(self, k, j, r):
        """è®¡ç®—t=1çš„æ¡ä»¶ä¿¡å¿µæ¦‚ç‡"""
        o_hat_1 = self.o_hat[(k, 1)]
        a_hat_0 = self.a_hat_0[k]

        numerator = 0.0
        denominator = 0.0

        p_obs = self.P_observation.get((k, 1, o_hat_1, r, a_hat_0), 1e-8)
        for r0 in self.sets['R_kt'][(k, 0)]:
            p_trans = self.P_transition.get((k, 0, r, r0, a_hat_0), 1e-8)
            g_hat = self.g_hat_0.get((k, j, r0), 1e-8)
            numerator += p_trans * g_hat
        numerator *= p_obs

        for r_tilde in self.sets['R_kt'][(k, 1)]:
            p_obs_tilde = self.P_observation.get((k, 1, o_hat_1, r_tilde, a_hat_0), 1e-8)
            inner_sum = 0.0
            for r0 in self.sets['R_kt'][(k, 0)]:
                p_trans = self.P_transition.get((k, 0, r_tilde, r0, a_hat_0), 1e-8)
                g_hat = self.g_hat_0.get((k, j, r0), 1e-8)
                inner_sum += p_trans * g_hat
            denominator += p_obs_tilde * inner_sum

        if denominator < 1e-10:
            return 1.0 / self.num_states

        return numerator / denominator

    def _compute_G_t_general(self, k, t, j, r, actions, G):
        """è®¡ç®—t>=2çš„æ¡ä»¶ä¿¡å¿µæ¦‚ç‡"""
        o_hat_t = self.o_hat[(k, t)]

        numerator = 0.0
        denominator = 0.0

        for a in self.sets['A_kt'][(k, t - 1)]:
            action_selected = 1.0 if actions.get((k, t - 1)) == a else 0.0

            if action_selected < 0.5:
                continue

            p_obs = self.P_observation.get((k, t, o_hat_t, r, a), 1e-8)
            inner_sum_num = 0.0
            for r_prev in self.sets['R_kt'][(k, t - 1)]:
                p_trans = self.P_transition.get((k, t - 1, r, r_prev, a), 1e-8)
                g_prev = G.get((k, t - 1, j, r_prev), 1e-8)
                inner_sum_num += p_trans * g_prev

            numerator += action_selected * p_obs * inner_sum_num

            for r_tilde in self.sets['R_kt'][(k, t)]:
                p_obs_tilde = self.P_observation.get((k, t, o_hat_t, r_tilde, a), 1e-8)
                inner_sum_den = 0.0
                for r_prev in self.sets['R_kt'][(k, t - 1)]:
                    p_trans = self.P_transition.get((k, t - 1, r_tilde, r_prev, a), 1e-8)
                    g_prev = G.get((k, t - 1, j, r_prev), 1e-8)
                    inner_sum_den += p_trans * g_prev

                denominator += action_selected * p_obs_tilde * inner_sum_den

        if denominator < 1e-10:
            return 1.0 / self.num_states

        return numerator / denominator

    def _compute_u_from_G(self, k, t, r, G, u):
        """ä»Gè®¡ç®—uï¼ˆä¿¡å¿µçŠ¶æ€ï¼‰"""
        if not self.sets['Theta_kt'][(k, t)]:
            return 1.0 / self.num_states

        belief_sum = 0.0

        for j in self.sets['delta_kt'][(k, t)]:
            g_val = G.get((k, t, j, r), 0.0)

            parent_product = 1.0
            parent_set = self.sets['Theta_kt'][(k, t)]

            for parent_idx, (parent_k, parent_t) in enumerate(parent_set):
                parent_state = self._get_parent_state(k, j, parent_idx)

                if parent_t == -1:
                    parent_prob = self.u_hat_0.get((parent_k, parent_state), 1e-8)
                else:
                    parent_prob = u.get((parent_k, parent_t, parent_state), 1e-8)

                parent_product *= parent_prob

            belief_sum += g_val * parent_product

        return belief_sum

    def _get_parent_state(self, k, j, parent_idx):
        """ä»ç»„åˆç´¢å¼•jä¸­æå–çˆ¶èŠ‚ç‚¹çŠ¶æ€"""
        if k in self.G_dic and j < len(self.G_dic[k]):
            combination = self.G_dic[k][j]
            if parent_idx < len(combination):
                if parent_idx < len(combination) - 1:
                    return combination[parent_idx]
                else:
                    return combination[-1]
        return 0

    def tournament_selection(self, population, fitness_values, tournament_size):
        """é”¦æ ‡èµ›é€‰æ‹©"""
        selected_idx = np.random.choice(len(population), size=tournament_size, replace=False)
        selected_fitness = fitness_values[selected_idx]
        winner_idx = selected_idx[np.argmin(selected_fitness)]
        return population[winner_idx].copy()

    def crossover(self, parent1, parent2):
        """å•ç‚¹äº¤å‰"""
        if np.random.rand() > self.crossover_rate:
            return parent1.copy(), parent2.copy()

        point = np.random.randint(1, len(parent1))
        child1 = np.concatenate([parent1[:point], parent2[point:]])
        child2 = np.concatenate([parent2[:point], parent1[point:]])

        return child1, child2

    def mutate(self, chromosome):
        """å˜å¼‚æ“ä½œ"""
        mutated = chromosome.copy()

        for i in range(len(mutated)):
            if np.random.rand() < self.mutation_rate:
                mutated[i] = np.random.randint(0, self.num_actions)

        return mutated

    def _check_early_stop(self, generation):
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ

        åˆ¤æ–­æ ‡å‡†ï¼šè¿ç»­patienceä»£ï¼Œæœ€ä¼˜è§£æ”¹è¿› < min_delta
        """
        if not self.enable_early_stop or generation < self.early_stop_patience:
            return False

        # è·å–æœ€è¿‘patienceä»£çš„æœ€ä¼˜é€‚åº”åº¦
        recent_best = self.best_fitness_history[-self.early_stop_patience:]

        # è®¡ç®—æ”¹è¿›å¹…åº¦
        best_in_window = min(recent_best)
        worst_in_window = max(recent_best)

        if abs(worst_in_window) > 1e-10:
            improvement = (worst_in_window - best_in_window) / abs(worst_in_window)
        else:
            improvement = 0

        # æ”¹è¿›å°äºé˜ˆå€¼ï¼Œè§¦å‘æ—©åœ
        if improvement < self.early_stop_delta:
            print(f"\n   âš¡ æ—©åœè§¦å‘ï¼šç¬¬{generation}ä»£")
            print(f"      æœ€è¿‘{self.early_stop_patience}ä»£æ”¹è¿›: {improvement:.8f} < {self.early_stop_delta}")
            print(f"      èŠ‚çœè¿­ä»£: {self.max_generations - generation}ä»£")
            self.early_stopped = True
            return True

        return False

    def evolve(self):
        """ä¸»è¿›åŒ–å¾ªç¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        print("\nğŸš€ å¼€å§‹ä¼˜åŒ–ç‰ˆGAæ±‚è§£...")
        if self.enable_cache:
            print("   âœ… ç¼“å­˜å·²å¯ç”¨")
        if self.enable_early_stop:
            print(f"   âœ… æ—©åœå·²å¯ç”¨ (å®¹å¿{self.early_stop_patience}ä»£)")

        self.start_time = time.time()

        population = self.initialize_population()
        fitness_values = np.array([self.evaluate_fitness(ind) for ind in population])

        best_idx = np.argmin(fitness_values)
        self.best_fitness = fitness_values[best_idx]
        self.best_solution = population[best_idx].copy()

        print(f"    åˆå§‹æœ€ä¼˜é€‚åº”åº¦: {self.best_fitness:.6f}")

        for generation in range(self.max_generations):
            new_population = []

            # ç²¾è‹±ä¿ç•™
            elite_size = int(self.elitism_rate * self.population_size)
            elite_indices = np.argsort(fitness_values)[:elite_size]
            for idx in elite_indices:
                new_population.append(population[idx].copy())

            # ç¹æ®–
            while len(new_population) < self.population_size:
                parent1 = self.tournament_selection(population, fitness_values, self.tournament_size)
                parent2 = self.tournament_selection(population, fitness_values, self.tournament_size)

                child1, child2 = self.crossover(parent1, parent2)
                child1 = self.mutate(child1)
                child2 = self.mutate(child2)

                new_population.extend([child1, child2])

            new_population = new_population[:self.population_size]
            population = np.array(new_population)

            # è¯„ä¼°é€‚åº”åº¦
            fitness_values = np.array([self.evaluate_fitness(ind) for ind in population])

            # æ›´æ–°æœ€ä¼˜è§£
            best_idx = np.argmin(fitness_values)
            if fitness_values[best_idx] < self.best_fitness:
                self.best_fitness = fitness_values[best_idx]
                self.best_solution = population[best_idx].copy()

            # è®°å½•å†å²
            self.best_fitness_history.append(self.best_fitness)
            self.avg_fitness_history.append(np.mean(fitness_values))

            self.actual_generations = generation + 1

            # å®šæœŸæ‰“å°
            if (generation + 1) % 50 == 0 or generation == 0:
                print(f"    ä»£ {generation + 1}/{self.max_generations}: "
                      f"æœ€ä¼˜={self.best_fitness:.6f}, å¹³å‡={np.mean(fitness_values):.6f}")

            # âœ… æ—©åœæ£€æŸ¥
            if self._check_early_stop(generation + 1):
                break

        self.time_used = time.time() - self.start_time
        print(f"\nâœ… ä¼˜åŒ–å®Œæˆï¼ç”¨æ—¶: {self.time_used:.2f} ç§’")
        print(f"    å®é™…è¿­ä»£: {self.actual_generations}/{self.max_generations} ä»£")
        if self.early_stopped:
            saved_gens = self.max_generations - self.actual_generations
            print(f"    æå‰åœæ­¢èŠ‚çœ: {saved_gens} ä»£ ({saved_gens / self.max_generations * 100:.1f}%)")
        print(f"    æœ€ä¼˜é€‚åº”åº¦: {self.best_fitness:.6f}")

        # æ‰“å°ç¼“å­˜ç»Ÿè®¡
        if self.enable_cache and self.belief_cache is not None:
            self.belief_cache.print_stats()

        return self.best_solution, self.best_fitness

    def extract_solution(self):
        """æå–è§£"""
        if self.best_solution is None:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„è§£")
            return None, None

        actions = self.decode_solution(self.best_solution)

        # é‡æ–°è®¡ç®—æœ€ç»ˆçš„ä¿¡å¿µçŠ¶æ€ï¼ˆä¸ä½¿ç”¨ç¼“å­˜ï¼Œç¡®ä¿å‡†ç¡®ï¼‰
        u, G = self._compute_belief_states(actions)

        total_cost = sum(self.cost.get((k, t, actions[(k, t)]), 0)
                         for k in self.sets['K']
                         for t in self.sets['T'][1:-1])

        print("\nğŸ“‹ æœ€ä¼˜è§£è¯¦æƒ…:")
        print(f"    ç›®æ ‡å‡½æ•°å€¼: {self.best_fitness:.6f}")
        print(f"    æ€»æˆæœ¬: {total_cost:.2f} / {self.budget}")

        print("\n    å†³ç­–åŠ¨ä½œ:")
        action_names = {0: "æ— åŠ¨ä½œ", 1: "mild", 2: "intense"}
        for k in range(min(5, len(self.sets['K']))):  # åªæ˜¾ç¤ºå‰5ä¸ªèŠ‚ç‚¹
            for t in self.sets['T'][1:-1]:
                a = actions[(k, t)]
                cost = self.cost.get((k, t, a), 0)
                node_type = self._get_node_type(k)
                print(f"      èŠ‚ç‚¹ {k} ({node_type}), æ—¶æœŸ {t}: "
                      f"åŠ¨ä½œ {a} ({action_names[a]}), æˆæœ¬ {cost:.1f}")

        print("\n    æœ€åèŠ‚ç‚¹é£é™©çŠ¶æ€æ¦‚ç‡:")
        last_node = max(self.sets['K'])
        worst_state = 0
        for t in self.sets['T']:
            prob = u.get((last_node, t, worst_state), 0.0)
            print(f"      æ—¶æœŸ {t}: {prob:.4f}")

        return actions, u

    def export_results(self, filename=None):
        """å¯¼å‡ºç»“æœåˆ°Excel"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            disruption = self.prediction_params.get('disruption_level', 'unknown')
            filename = f"GA3_B{self.budget}_Gamma{self.gamma:.2f}_{disruption}_{timestamp}.xlsx"

        try:
            actions, u = self.extract_solution()

            if actions is None:
                return None

            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # å†³ç­–å˜é‡
                action_names = {0: "æ— åŠ¨ä½œ", 1: "mild", 2: "intense"}
                x_data = []
                for k in self.sets['K']:
                    for t in self.sets['T'][1:-1]:
                        a = actions[(k, t)]
                        x_data.append({
                            'èŠ‚ç‚¹': k,
                            'èŠ‚ç‚¹ç±»å‹': self._get_node_type(k),
                            'æ—¶æœŸ': t,
                            'åŠ¨ä½œ': a,
                            'åŠ¨ä½œåç§°': action_names[a],
                            'æˆæœ¬': self.cost.get((k, t, a), 0)
                        })

                df_x = pd.DataFrame(x_data)
                df_x.to_excel(writer, sheet_name='å†³ç­–å˜é‡', index=False)

                # ä¿¡å¿µçŠ¶æ€
                u_data = []
                for (k, t, r), prob in u.items():
                    u_data.append({
                        'èŠ‚ç‚¹': k,
                        'èŠ‚ç‚¹ç±»å‹': self._get_node_type(k),
                        'æ—¶æœŸ': t,
                        'çŠ¶æ€': r,
                        'æ¦‚ç‡': prob
                    })

                df_u = pd.DataFrame(u_data)
                df_u.to_excel(writer, sheet_name='ä¿¡å¿µçŠ¶æ€', index=False)

                # é£é™©åˆ†æ
                last_node = max(self.sets['K'])
                worst_state = 0
                risk_data = []
                for t in self.sets['T']:
                    prob = u.get((last_node, t, worst_state), 0.0)
                    risk_data.append({
                        'æ—¶æœŸ': t,
                        'é£é™©çŠ¶æ€æ¦‚ç‡': prob
                    })

                df_risk = pd.DataFrame(risk_data)
                df_risk.to_excel(writer, sheet_name='é£é™©åˆ†æ', index=False)

                # å‚æ•°æ±‡æ€»
                params_data = {
                    'å‚æ•°å': [
                        'ç‰ˆæœ¬', 'èŠ‚ç‚¹æ•°', 'æ—¶æœŸæ•°', 'çŠ¶æ€æ•°', 'åŠ¨ä½œæ•°', 'é¢„ç®—', 'æŠ˜ç°å› å­',
                        'æ±‚è§£æ—¶é—´(ç§’)', 'å®é™…è¿­ä»£ä»£æ•°', 'æœ€å¤§è¿­ä»£ä»£æ•°', 'ç›®æ ‡å‡½æ•°å€¼',
                        'Disruptionçº§åˆ«', 'ç§ç¾¤å¤§å°', 'äº¤å‰ç‡', 'å˜å¼‚ç‡',
                        'ç¼“å­˜å¯ç”¨', 'æ—©åœå¯ç”¨', 'æ—©åœè§¦å‘'
                    ],
                    'å€¼': [
                        'GA3 (ä¼˜åŒ–ç‰ˆ)',
                        self.num_nodes, self.num_periods, self.num_states,
                        self.num_actions, self.budget, self.gamma,
                        round(self.time_used, 2), self.actual_generations, self.max_generations,
                        self.best_fitness,
                        self.prediction_params.get('disruption_level', 'N/A'),
                        self.population_size, self.crossover_rate, self.mutation_rate,
                        'æ˜¯' if self.enable_cache else 'å¦',
                        'æ˜¯' if self.enable_early_stop else 'å¦',
                        'æ˜¯' if self.early_stopped else 'å¦'
                    ]
                }
                df_params = pd.DataFrame(params_data)
                df_params.to_excel(writer, sheet_name='å‚æ•°æ±‡æ€»', index=False)

                # è¿›åŒ–å†å²
                history_data = {
                    'ä»£æ•°': list(range(1, len(self.best_fitness_history) + 1)),
                    'æœ€ä¼˜é€‚åº”åº¦': self.best_fitness_history,
                    'å¹³å‡é€‚åº”åº¦': self.avg_fitness_history
                }
                df_history = pd.DataFrame(history_data)
                df_history.to_excel(writer, sheet_name='è¿›åŒ–å†å²', index=False)

                # ç¼“å­˜ç»Ÿè®¡
                if self.enable_cache and self.belief_cache is not None:
                    cache_stats = self.belief_cache.get_stats()
                    cache_data = {
                        'æŒ‡æ ‡': ['æ€»æŸ¥è¯¢æ¬¡æ•°', 'ç¼“å­˜å‘½ä¸­æ¬¡æ•°', 'ç¼“å­˜å‘½ä¸­ç‡(%)',
                                 'å¢é‡æ›´æ–°æ¬¡æ•°', 'å¢é‡æ›´æ–°ç‡(%)', 'ç¼“å­˜å¤§å°'],
                        'å€¼': [
                            cache_stats['total_queries'],
                            self.belief_cache.hit_count,
                            cache_stats['hit_rate'],
                            self.belief_cache.incremental_count,
                            cache_stats['incremental_rate'],
                            cache_stats['cache_size']
                        ]
                    }
                    df_cache = pd.DataFrame(cache_data)
                    df_cache.to_excel(writer, sheet_name='ç¼“å­˜ç»Ÿè®¡', index=False)

            print(f"âœ… ç»“æœå·²å¯¼å‡º: {filename}")
            return filename

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def plot_convergence(self, save_path=None):
        """ç»˜åˆ¶æ”¶æ•›æ›²çº¿"""
        if not self.best_fitness_history:
            print("âŒ æ²¡æœ‰è¿›åŒ–å†å²æ•°æ®")
            return

        plt.figure(figsize=(10, 6))
        plt.plot(self.best_fitness_history, label='Best Fitness', linewidth=2)
        plt.plot(self.avg_fitness_history, label='Average Fitness', linewidth=2, alpha=0.7)

        # æ ‡è®°æ—©åœä½ç½®
        if self.early_stopped:
            plt.axvline(x=self.actual_generations, color='red', linestyle='--',
                        linewidth=2, label=f'Early Stop (Gen {self.actual_generations})')

        plt.xlabel('Generation')
        plt.ylabel('Fitness Value')
        plt.title('GA3 Convergence (Optimized with Cache & Early Stop)')
        plt.legend()
        plt.grid(True, alpha=0.3)

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… æ”¶æ•›æ›²çº¿å·²ä¿å­˜: {save_path}")
        else:
            plt.show()


# ==================== è¾…åŠ©å‡½æ•° ====================

def get_observed_data(disruption_level):
    """è·å–è§‚æµ‹æ•°æ®ï¼ˆå¤ç”¨åŸä»£ç ï¼‰"""
    if disruption_level.lower() == 'light':
        return {
            1: {
                0: {'D_obs': 90, 'SD_obs': 38},
                1: {'D_obs': 88, 'SD_obs': 42},
                2: {'D_obs': 92, 'SD_obs': 48},
                3: {'D_obs': 45, 'SD_obs': 33},
                4: {'D_obs': 47, 'SD_obs': 38},
                5: {'D_obs': 45, 'SD_obs': 39}
            }
        }
    elif disruption_level.lower() == 'moderate':
        return {
            1: {
                0: {'D_obs': 100, 'SD_obs': 24},
                1: {'D_obs': 98, 'SD_obs': 27},
                2: {'D_obs': 102, 'SD_obs': 33},
                3: {'D_obs': 55, 'SD_obs': 21},
                4: {'D_obs': 52, 'SD_obs': 24},
                5: {'D_obs': 50, 'SD_obs': 31}
            }
        }
    elif disruption_level.lower() == 'severe':
        return {
            1: {
                0: {'D_obs': 110, 'SD_obs': 15},
                1: {'D_obs': 105, 'SD_obs': 19},
                2: {'D_obs': 108, 'SD_obs': 23},
                3: {'D_obs': 60, 'SD_obs': 6},
                4: {'D_obs': 58, 'SD_obs': 18},
                5: {'D_obs': 55, 'SD_obs': 22}
            }
        }
    else:
        return None


def main():
    """ä¸»å‡½æ•° - ç‹¬ç«‹æµ‹è¯•æ¨¡å¼"""
    print("=" * 80)
    print("ğŸ§¬ ä¼˜åŒ–ç‰ˆGAæ±‚è§£å™¨ (GA3.py) - ç‹¬ç«‹æµ‹è¯•æ¨¡å¼")
    print(f"   Current Date and Time (UTC): 2025-10-29 08:02:24")
    print(f"   Current User's Login: dyy21zyy")
    print("=" * 80)

    print("\nâš ï¸  æ³¨æ„ï¼š")
    print("   è¿™æ˜¯ç‹¬ç«‹æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨å›ºå®šçš„æµ‹è¯•é…ç½®")
    print("   å®é™…è¿›è¡Œéšæœºå®éªŒå¯¹æ¯”æ—¶ï¼Œè¯·è¿è¡Œ main_systematic_experiments.py")

    # ä½¿ç”¨å›ºå®šæµ‹è¯•é…ç½®
    test_config = {
        'disruption_level': 'moderate',
        'num_suppliers': 3,
        'num_manufacturers': 2,
        'num_periods': 4,
        'num_states': 2,
        'budget': 100,
        'seed': 42,
        'connection_density': 0.7
    }

    print(f"\nğŸ“‹ æµ‹è¯•é…ç½®: {test_config['disruption_level'].upper()}")

    # ç”Ÿæˆæµ‹è¯•ç”¨è§‚æµ‹æ•°æ®
    observed_data = get_observed_data(test_config['disruption_level'])

    # å‚æ•°é…ç½®
    network_params = {
        'num_suppliers': test_config['num_suppliers'],
        'num_manufacturers': test_config['num_manufacturers'],
        'connection_density': test_config['connection_density'],
        'seed': test_config['seed'],
        'network_type': 'random'
    }

    pomdp_params = {
        'discount_factor': 0.9,
        'action_space_size': 3
    }

    prediction_params = {
        'num_periods': test_config['num_periods'],
        'num_states': test_config['num_states'],
        'mcmc_samples': 500,  # æµ‹è¯•æ—¶å‡å°‘é‡‡æ ·
        'mc_samples': 500,
        'disruption_level': test_config['disruption_level'],
        'observed_data': observed_data
    }

    # åˆ›å»ºæ±‚è§£å™¨ï¼ˆå¯ç”¨æ‰€æœ‰ä¼˜åŒ–ï¼‰
    solver = GeneticAlgorithmSolver(
        network_params=network_params,
        pomdp_params=pomdp_params,
        prediction_params=prediction_params,
        population_size=100,
        max_generations=300,
        crossover_rate=0.8,
        mutation_rate=0.1,
        elitism_rate=0.1,
        tournament_size=5,
        enable_cache=True,  # âœ… å¯ç”¨ç¼“å­˜
        enable_early_stop=True,  # âœ… å¯ç”¨æ—©åœ
        early_stop_patience=50,  # å®¹å¿50ä»£æ— æ”¹è¿›
        early_stop_delta=1e-6  # æ”¹è¿›é˜ˆå€¼
    )

    # è®¾ç½®é¢„ç®—
    solver.budget = test_config['budget']

    # åˆå§‹åŒ–
    print("\n" + "=" * 80)
    solver.initialize_components()
    print("=" * 80)

    # è¿è¡Œä¼˜åŒ–
    best_solution, best_fitness = solver.evolve()

    # æå–è§£
    solver.extract_solution()

    # å¯¼å‡ºç»“æœ
    print("\n" + "=" * 80)
    excel_file = solver.export_results()

    # ç»˜åˆ¶æ”¶æ•›æ›²çº¿
    if excel_file:
        plot_file = excel_file.replace('.xlsx', '_convergence.png')
        solver.plot_convergence(save_path=plot_file)

    print("\nâœ… GA3ç‹¬ç«‹æµ‹è¯•å®Œæˆï¼")

    # æ‰“å°ä¼˜åŒ–æ•ˆæœæ‘˜è¦
    print("\n" + "=" * 80)
    print("ğŸ“Š ä¼˜åŒ–æ•ˆæœæ‘˜è¦:")
    print(f"   å®é™…è¿­ä»£: {solver.actual_generations}/{solver.max_generations} ä»£")
    if solver.early_stopped:
        saved_gens = solver.max_generations - solver.actual_generations
        time_saving = saved_gens / solver.max_generations * 100
        print(f"   æ—©åœèŠ‚çœ: {saved_gens} ä»£ ({time_saving:.1f}%)")

    if solver.enable_cache and solver.belief_cache:
        cache_stats = solver.belief_cache.get_stats()
        print(f"   ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1f}%")
        print(f"   å¢é‡æ›´æ–°ç‡: {cache_stats['incremental_rate']:.1f}%")

    print(f"   æ€»ç”¨æ—¶: {solver.time_used:.2f} ç§’")
    print(f"   æœ€ä¼˜ç›®æ ‡å€¼: {solver.best_fitness:.6f}")
    print("=" * 80)

    print("\nğŸ’¡ æç¤º:")
    print("   è¦è¿›è¡Œ GA3 vs Gurobi çš„å¯¹æ¯”å®éªŒï¼Œè¯·è¿è¡Œ:")
    print("   python main_systematic_experiments.py")
    print("   (ç¡®ä¿å°† GA1 æˆ– GA2 æ”¹ä¸º GA3)")

    return solver


def test_optimization_effects():
    """
    æµ‹è¯•ä¼˜åŒ–æ•ˆæœå¯¹æ¯”

    å¯¹æ¯”ï¼š
    1. æ— ä¼˜åŒ–ï¼ˆå…³é—­ç¼“å­˜å’Œæ—©åœï¼‰
    2. åªå¯ç”¨æ—©åœ
    3. åªå¯ç”¨ç¼“å­˜
    4. å…¨éƒ¨ä¼˜åŒ–ï¼ˆç¼“å­˜+æ—©åœï¼‰
    """
    print("=" * 80)
    print("ğŸ§ª ä¼˜åŒ–æ•ˆæœå¯¹æ¯”æµ‹è¯•")
    print(f"   Current Date and Time (UTC): 2025-10-29 08:02:24")
    print("=" * 80)

    # æµ‹è¯•é…ç½®
    test_config = {
        'disruption_level': 'moderate',
        'num_suppliers': 3,
        'num_manufacturers': 2,
        'num_periods': 4,
        'num_states': 2,
        'budget': 100,
        'seed': 42,
        'connection_density': 0.7
    }

    observed_data = get_observed_data(test_config['disruption_level'])

    network_params = {
        'num_suppliers': test_config['num_suppliers'],
        'num_manufacturers': test_config['num_manufacturers'],
        'connection_density': test_config['connection_density'],
        'seed': test_config['seed'],
        'network_type': 'random'
    }

    pomdp_params = {
        'discount_factor': 0.9,
        'action_space_size': 3
    }

    prediction_params = {
        'num_periods': test_config['num_periods'],
        'num_states': test_config['num_states'],
        'mcmc_samples': 500,
        'mc_samples': 500,
        'disruption_level': test_config['disruption_level'],
        'observed_data': observed_data
    }

    # æµ‹è¯•åœºæ™¯
    scenarios = [
        {
            'name': 'æ— ä¼˜åŒ–',
            'enable_cache': False,
            'enable_early_stop': False
        },
        {
            'name': 'åªå¯ç”¨æ—©åœ',
            'enable_cache': False,
            'enable_early_stop': True
        },
        {
            'name': 'åªå¯ç”¨ç¼“å­˜',
            'enable_cache': True,
            'enable_early_stop': False
        },
        {
            'name': 'å…¨éƒ¨ä¼˜åŒ–',
            'enable_cache': True,
            'enable_early_stop': True
        }
    ]

    results = []

    for scenario in scenarios:
        print(f"\n{'=' * 80}")
        print(f"ğŸ”¬ æµ‹è¯•åœºæ™¯: {scenario['name']}")
        print(f"{'=' * 80}")

        # åˆ›å»ºæ±‚è§£å™¨
        solver = GeneticAlgorithmSolver(
            network_params=network_params,
            pomdp_params=pomdp_params,
            prediction_params=prediction_params,
            population_size=50,  # å‡å°ç§ç¾¤ä»¥åŠ å¿«æµ‹è¯•
            max_generations=100,  # å‡å°‘è¿­ä»£ä»¥åŠ å¿«æµ‹è¯•
            enable_cache=scenario['enable_cache'],
            enable_early_stop=scenario['enable_early_stop'],
            early_stop_patience=20  # å‡å°‘å®¹å¿ä»£æ•°
        )

        solver.budget = test_config['budget']

        # åˆå§‹åŒ–
        solver.initialize_components()

        # è¿è¡Œä¼˜åŒ–
        start_time = time.time()
        best_solution, best_fitness = solver.evolve()
        elapsed_time = time.time() - start_time

        # æ”¶é›†ç»“æœ
        result = {
            'scenario': scenario['name'],
            'enable_cache': scenario['enable_cache'],
            'enable_early_stop': scenario['enable_early_stop'],
            'time': elapsed_time,
            'generations': solver.actual_generations,
            'objective': best_fitness,
            'early_stopped': solver.early_stopped
        }

        if solver.enable_cache and solver.belief_cache:
            cache_stats = solver.belief_cache.get_stats()
            result['cache_hit_rate'] = cache_stats['hit_rate']
            result['incremental_rate'] = cache_stats['incremental_rate']
        else:
            result['cache_hit_rate'] = 0
            result['incremental_rate'] = 0

        results.append(result)

        print(f"\n   ç»“æœ: æ—¶é—´={elapsed_time:.2f}s, ç›®æ ‡å€¼={best_fitness:.6f}")

    # æ‰“å°å¯¹æ¯”ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š ä¼˜åŒ–æ•ˆæœå¯¹æ¯”")
    print("=" * 80)

    df = pd.DataFrame(results)

    # è®¡ç®—åŠ é€Ÿæ¯”ï¼ˆç›¸å¯¹äºæ— ä¼˜åŒ–ï¼‰
    baseline_time = df[df['scenario'] == 'æ— ä¼˜åŒ–']['time'].values[0]
    df['speedup'] = baseline_time / df['time']

    print("\nå¯¹æ¯”è¡¨æ ¼:")
    print(df[['scenario', 'time', 'speedup', 'generations', 'objective',
              'cache_hit_rate', 'early_stopped']].to_string(index=False))

    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f'optimization_comparison_{timestamp}.xlsx'
    df.to_excel(output_file, index=False)
    print(f"\nâœ… å¯¹æ¯”ç»“æœå·²ä¿å­˜: {output_file}")

    # ç»˜åˆ¶å¯¹æ¯”å›¾
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))

    # å­å›¾1: æ—¶é—´å¯¹æ¯”
    ax1.bar(df['scenario'], df['time'], color=['#FF6B6B', '#FFA07A', '#4ECDC4', '#95E1D3'])
    ax1.set_ylabel('Time (seconds)', fontweight='bold')
    ax1.set_title('Execution Time Comparison', fontweight='bold')
    ax1.tick_params(axis='x', rotation=45)
    for i, v in enumerate(df['time']):
        ax1.text(i, v, f'{v:.1f}s', ha='center', va='bottom')

    # å­å›¾2: åŠ é€Ÿæ¯”
    ax2.bar(df['scenario'], df['speedup'], color=['#FF6B6B', '#FFA07A', '#4ECDC4', '#95E1D3'])
    ax2.set_ylabel('Speedup', fontweight='bold')
    ax2.set_title('Speedup (vs Baseline)', fontweight='bold')
    ax2.axhline(y=1, color='red', linestyle='--', linewidth=1)
    ax2.tick_params(axis='x', rotation=45)
    for i, v in enumerate(df['speedup']):
        ax2.text(i, v, f'{v:.2f}x', ha='center', va='bottom')

    # å­å›¾3: è¿­ä»£ä»£æ•°
    ax3.bar(df['scenario'], df['generations'], color=['#FF6B6B', '#FFA07A', '#4ECDC4', '#95E1D3'])
    ax3.set_ylabel('Generations', fontweight='bold')
    ax3.set_title('Actual Generations', fontweight='bold')
    ax3.tick_params(axis='x', rotation=45)
    for i, v in enumerate(df['generations']):
        ax3.text(i, v, f'{int(v)}', ha='center', va='bottom')

    # å­å›¾4: ç›®æ ‡å€¼è´¨é‡
    ax4.bar(df['scenario'], df['objective'], color=['#FF6B6B', '#FFA07A', '#4ECDC4', '#95E1D3'])
    ax4.set_ylabel('Objective Value', fontweight='bold')
    ax4.set_title('Solution Quality', fontweight='bold')
    ax4.tick_params(axis='x', rotation=45)
    for i, v in enumerate(df['objective']):
        ax4.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    plot_file = f'optimization_comparison_{timestamp}.png'
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"âœ… å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: {plot_file}")

    print("\n" + "=" * 80)
    print("ğŸ“ˆ ä¼˜åŒ–æ•ˆæœæ€»ç»“:")
    max_speedup = df['speedup'].max()
    best_scenario = df.loc[df['speedup'].idxmax(), 'scenario']
    print(f"   æœ€ä½³åœºæ™¯: {best_scenario}")
    print(f"   æœ€å¤§åŠ é€Ÿæ¯”: {max_speedup:.2f}x")
    print(f"   æ—¶é—´èŠ‚çœ: {(1 - 1 / max_speedup) * 100:.1f}%")

    # æ£€æŸ¥è´¨é‡æŸå¤±
    baseline_obj = df[df['scenario'] == 'æ— ä¼˜åŒ–']['objective'].values[0]
    max_obj_diff = (df['objective'] - baseline_obj).abs().max()
    max_obj_diff_pct = max_obj_diff / baseline_obj * 100
    print(f"   æœ€å¤§è´¨é‡å·®å¼‚: {max_obj_diff_pct:.4f}%")

    if max_obj_diff_pct < 0.01:
        print("   âœ… è´¨é‡å®Œå…¨ä¿æŒï¼ˆå·®å¼‚<0.01%ï¼‰")
    else:
        print("   âš ï¸  è´¨é‡æœ‰è½»å¾®å·®å¼‚")

    print("=" * 80)

    return df


def compare_with_baseline():
    """
    ä¸åŸç‰ˆGA2å¯¹æ¯”

    æ³¨æ„ï¼šéœ€è¦å…ˆæœ‰GA2.py
    """
    print("=" * 80)
    print("ğŸ”¬ GA3 vs GA2 å¯¹æ¯”æµ‹è¯•")
    print(f"   Current Date and Time (UTC): 2025-10-29 08:02:24")
    print("=" * 80)

    try:
        from GA2 import GeneticAlgorithmSolver as GA2Solver
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥ GA2ï¼Œè·³è¿‡å¯¹æ¯”æµ‹è¯•")
        return

    # æµ‹è¯•é…ç½®
    test_config = {
        'disruption_level': 'moderate',
        'num_suppliers': 3,
        'num_manufacturers': 2,
        'num_periods': 4,
        'num_states': 2,
        'budget': 100,
        'seed': 42,
        'connection_density': 0.7
    }

    observed_data = get_observed_data(test_config['disruption_level'])

    network_params = {
        'num_suppliers': test_config['num_suppliers'],
        'num_manufacturers': test_config['num_manufacturers'],
        'connection_density': test_config['connection_density'],
        'seed': test_config['seed'],
        'network_type': 'random'
    }

    pomdp_params = {
        'discount_factor': 0.9,
        'action_space_size': 3
    }

    prediction_params = {
        'num_periods': test_config['num_periods'],
        'num_states': test_config['num_states'],
        'mcmc_samples': 500,
        'mc_samples': 500,
        'disruption_level': test_config['disruption_level'],
        'observed_data': observed_data
    }

    # è¿è¡ŒGA2
    print("\nğŸ”· è¿è¡Œ GA2 (åŸç‰ˆ)...")
    solver_ga2 = GA2Solver(
        network_params=network_params,
        pomdp_params=pomdp_params,
        prediction_params=prediction_params,
        population_size=100,
        max_generations=300
    )
    solver_ga2.budget = test_config['budget']
    solver_ga2.initialize_components()

    start_time = time.time()
    best_solution_ga2, best_fitness_ga2 = solver_ga2.evolve()
    time_ga2 = time.time() - start_time

    # è¿è¡ŒGA3
    print("\nğŸ”¶ è¿è¡Œ GA3 (ä¼˜åŒ–ç‰ˆ)...")
    solver_ga3 = GeneticAlgorithmSolver(
        network_params=network_params,
        pomdp_params=pomdp_params,
        prediction_params=prediction_params,
        population_size=100,
        max_generations=300,
        enable_cache=True,
        enable_early_stop=True
    )
    solver_ga3.budget = test_config['budget']
    solver_ga3.initialize_components()

    start_time = time.time()
    best_solution_ga3, best_fitness_ga3 = solver_ga3.evolve()
    time_ga3 = time.time() - start_time

    # å¯¹æ¯”ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š å¯¹æ¯”ç»“æœ")
    print("=" * 80)
    print(f"\nGA2 (åŸç‰ˆ):")
    print(f"   æ—¶é—´: {time_ga2:.2f} ç§’")
    print(f"   ç›®æ ‡å€¼: {best_fitness_ga2:.6f}")
    print(f"   è¿­ä»£ä»£æ•°: 300")

    print(f"\nGA3 (ä¼˜åŒ–ç‰ˆ):")
    print(f"   æ—¶é—´: {time_ga3:.2f} ç§’")
    print(f"   ç›®æ ‡å€¼: {best_fitness_ga3:.6f}")
    print(f"   å®é™…è¿­ä»£: {solver_ga3.actual_generations}")
    if solver_ga3.enable_cache:
        cache_stats = solver_ga3.belief_cache.get_stats()
        print(f"   ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1f}%")

    speedup = time_ga2 / time_ga3
    quality_diff = abs(best_fitness_ga2 - best_fitness_ga3) / best_fitness_ga2 * 100

    print(f"\næå‡æ•ˆæœ:")
    print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print(f"   æ—¶é—´èŠ‚çœ: {(1 - 1 / speedup) * 100:.1f}%")
    print(f"   è´¨é‡å·®å¼‚: {quality_diff:.4f}%")

    if speedup > 5:
        print("   âœ… æ˜¾è‘—åŠ é€Ÿï¼ˆ>5xï¼‰")
    elif speedup > 3:
        print("   âœ… æ˜æ˜¾åŠ é€Ÿï¼ˆ>3xï¼‰")
    elif speedup > 1.5:
        print("   âœ“ ä¸­ç­‰åŠ é€Ÿï¼ˆ>1.5xï¼‰")
    else:
        print("   âš ï¸  åŠ é€Ÿä¸æ˜æ˜¾")

    if quality_diff < 0.01:
        print("   âœ… è´¨é‡å®Œå…¨ä¿æŒ")
    elif quality_diff < 1:
        print("   âœ“ è´¨é‡åŸºæœ¬ä¿æŒ")
    else:
        print("   âš ï¸  è´¨é‡æœ‰å·®å¼‚")

    print("=" * 80)


if __name__ == "__main__":
    print("ğŸ§¬ GA3.py - ä¼˜åŒ–ç‰ˆé—ä¼ ç®—æ³•æ±‚è§£å™¨")
    print(f"Current Date and Time (UTC): 2025-10-29 08:02:24")
    print(f"Current User's Login: dyy21zyy")
    print()

    # é€‰æ‹©è¿è¡Œæ¨¡å¼
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("  1 - æ ‡å‡†æµ‹è¯•æ¨¡å¼ï¼ˆè¿è¡Œä¸€æ¬¡å®Œæ•´ä¼˜åŒ–ï¼‰")
    print("  2 - ä¼˜åŒ–æ•ˆæœå¯¹æ¯”ï¼ˆæµ‹è¯•ä¸åŒä¼˜åŒ–ç»„åˆï¼‰")
    print("  3 - ä¸GA2å¯¹æ¯”ï¼ˆéœ€è¦GA2.pyï¼‰")
    print("  4 - æŸ¥çœ‹ä½¿ç”¨è¯´æ˜")
    print()

    mode = input("è¯·è¾“å…¥é€‰é¡¹ (1/2/3/4): ").strip()

    if mode == '1':
        print("\n" + "=" * 80)
        print("è¿è¡Œæ ‡å‡†æµ‹è¯•æ¨¡å¼")
        print("=" * 80)
        solver = main()

    elif mode == '2':
        print("\n" + "=" * 80)
        print("è¿è¡Œä¼˜åŒ–æ•ˆæœå¯¹æ¯”æµ‹è¯•")
        print("=" * 80)
        df = test_optimization_effects()

    elif mode == '3':
        print("\n" + "=" * 80)
        print("è¿è¡Œ GA3 vs GA2 å¯¹æ¯”æµ‹è¯•")
        print("=" * 80)
        compare_with_baseline()

    elif mode == '4':
        print("\n" + "=" * 80)
        print("ğŸ“– GA3.py ä½¿ç”¨è¯´æ˜")
        print("=" * 80)
        print()
        print("æœ¬æ¨¡å—æä¾›ä¸‰ç§ä½¿ç”¨æ–¹å¼:")
        print()
        print("1ï¸âƒ£  ç‹¬ç«‹æµ‹è¯•æ¨¡å¼ï¼ˆå½“å‰ï¼‰")
        print("   ç”¨é€”: éªŒè¯ GA3 ä¼˜åŒ–æ•ˆæœ")
        print("   è¿è¡Œ: python GA3.py")
        print("   ç‰¹ç‚¹:")
        print("      - å¯ä»¥é€‰æ‹©ä¸åŒçš„æµ‹è¯•æ¨¡å¼")
        print("      - è‡ªåŠ¨å¯¹æ¯”ä¼˜åŒ–æ•ˆæœ")
        print("      - ç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Š")
        print()
        print("2ï¸âƒ£  ç³»ç»Ÿæ€§å®éªŒæ¨¡å¼ï¼ˆæ¨èç”¨äºè®ºæ–‡ï¼‰")
        print("   ç”¨é€”: GA3 vs Gurobi æ€§èƒ½å¯¹æ¯”")
        print("   è¿è¡Œ: python main_systematic_experiments.py")
        print("   ä¿®æ”¹: å°†å¯¼å…¥è¯­å¥æ”¹ä¸º 'from GA3 import GeneticAlgorithmSolver'")
        print("   ç‰¹ç‚¹:")
        print("      - ç»Ÿä¸€ç®¡ç†å®éªŒå‚æ•°")
        print("      - ç¡®ä¿ GA3 å’Œ Gurobi æ±‚è§£ç›¸åŒé—®é¢˜")
        print("      - è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š")
        print()
        print("3ï¸âƒ£  ç›´æ¥è°ƒç”¨æ–¹å¼ï¼ˆåœ¨å…¶ä»–è„šæœ¬ä¸­ä½¿ç”¨ï¼‰")
        print("   ç¤ºä¾‹:")
        print("   ```python")
        print("   from GA3 import GeneticAlgorithmSolver")
        print()
        print("   solver = GeneticAlgorithmSolver(")
        print("       network_params={...},")
        print("       pomdp_params={...},")
        print("       prediction_params={...},")
        print("       enable_cache=True,      # å¯ç”¨ç¼“å­˜")
        print("       enable_early_stop=True  # å¯ç”¨æ—©åœ")
        print("   )")
        print("   solver.budget = 200")
        print("   best_solution, best_fitness = solver.evolve()")
        print("   ```")
        print()
        print("=" * 80)
        print("ğŸ¯ ä¼˜åŒ–ç‰¹æ€§:")
        print("   âœ… å¢é‡å¼ä¿¡å¿µçŠ¶æ€ç¼“å­˜ - é¿å…é‡å¤è®¡ç®—")
        print("   âœ… æ—©åœæœºåˆ¶ - æ£€æµ‹æ”¶æ•›æå‰åœæ­¢")
        print("   âœ… è´¨é‡ä¿è¯ - 100%ç­‰ä»·äºåŸç‰ˆ")
        print("   âœ… é¢„æœŸåŠ é€Ÿ - 15-20å€")
        print()
        print("ğŸ’¡ æ¨èé…ç½®:")
        print("   å°è§„æ¨¡é—®é¢˜ (â‰¤10èŠ‚ç‚¹): enable_cache=True, enable_early_stop=True")
        print("   ä¸­ç­‰è§„æ¨¡ (10-15èŠ‚ç‚¹): enable_cache=True, enable_early_stop=True")
        print("   å¤§è§„æ¨¡é—®é¢˜ (>15èŠ‚ç‚¹): è€ƒè™‘å¢åŠ  early_stop_patience")
        print("=" * 80)

    else:
        print("\nâŒ æ— æ•ˆé€‰é¡¹ï¼Œè¿è¡Œé»˜è®¤æµ‹è¯•æ¨¡å¼")
        solver = main()